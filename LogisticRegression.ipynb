{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#THEORY"
      ],
      "metadata": {
        "id": "xRu3Q_6HWX21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7Rhwxh9xBBl"
      },
      "outputs": [],
      "source": [
        "#1.what is decision tree , and how does it work ?\n",
        "A Decision Tree is a popular machine learning algorithm used for both classification and regression tasks. It’s a supervised learning model that splits the data into subsets based on different feature values in a way that it can make predictions. Think of it as a flowchart where each internal node represents a decision based on a feature, and each leaf node represents an outcome or prediction.\n",
        "\n",
        "Key Concepts:\n",
        "Root Node: The starting point of the tree where all the data is at first considered.\n",
        "Decision Nodes: These are the nodes where the data gets split based on a feature’s value.\n",
        "Leaf Nodes: The final outcome or predicted class/target value at the end of a path.\n",
        "Branches: The pathways between nodes that show the outcome of a decision rule.\n",
        "How a Decision Tree Works:\n",
        "Data Splitting: The tree is built by recursively splitting the data into subsets based on a certain feature. The goal is to create pure subsets (where data points belong to one class or have similar target values).\n",
        "\n",
        "Choosing the Best Split: To decide how to split the data, the algorithm uses a metric to determine the best feature to split on. Common metrics include:\n",
        "\n",
        "Gini Impurity (for classification): Measures the \"impurity\" of the node; the lower the Gini score, the purer the node.\n",
        "Entropy (for classification): Measures the disorder or unpredictability in the data; lower entropy means more predictable.\n",
        "Mean Squared Error (MSE) (for regression): Measures the variance within the subset; lower MSE means the model is more precise.\n",
        "Stopping Criteria: The tree-building process stops when:\n",
        "\n",
        "A node has only data points from one class (for classification) or the variance is small (for regression).\n",
        "A predefined maximum depth of the tree is reached.\n",
        "Further splits don’t improve the model.\n",
        "Prediction: To make a prediction, a new data point is passed down the tree, following the decision rules until it reaches a leaf node. The prediction is based on the majority class (for classification) or the average value (for regression) in that leaf node.\n",
        "\n",
        "Example:\n",
        "Imagine you're building a decision tree to predict whether someone will buy a product based on features like \"age\" and \"income.\" Here’s how it might work:\n",
        "\n",
        "Start with the root node: The algorithm checks \"income\" first, as it may be the most informative feature.\n",
        "If the income is above a certain threshold, it branches to one side; if it’s below that threshold, it branches to the other side.\n",
        "Each branch would then look at another feature, like \"age\", and keep branching until it reaches a leaf that either says “will buy” or “won’t buy.”\n",
        "Advantages of Decision Trees:\n",
        "Interpretability: Easy to understand and visualize, which makes them user-friendly.\n",
        "No Data Preprocessing Required: Can handle both numerical and categorical data without needing to scale or normalize.\n",
        "Versatile: Can be used for classification and regression tasks.\n",
        "Disadvantages:\n",
        "Overfitting: Decision trees are prone to overfitting, especially with complex trees that fit too closely to the training data.\n",
        "Instability: Small changes in the data can result in a completely different tree.\n",
        "Bias toward features with more levels: The algorithm may favor features with more categories or levels when splitting.\n",
        "Example Workflow:\n",
        "You train a decision tree on a dataset.\n",
        "The algorithm splits the data based on the best features.\n",
        "The tree continues splitting until certain stopping conditions are met.\n",
        "When you want to make a prediction, you simply follow the tree from top to bottom, making decisions based on the data point's features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. what are impurities measures in decision trees?\n",
        "In decision trees, impurity measures are used to evaluate how \"impure\" a node is, and they help guide the tree-building process by deciding which feature and value to split on. The goal is to split the data at each node in a way that leads to pure subsets (where the data points in each subset are similar to each other). The more \"pure\" a node is, the better it is at making accurate predictions.\n",
        "\n",
        "There are several common impurity measures used in decision trees:\n",
        "\n",
        "1. Gini Impurity (used in Classification)\n",
        "The Gini Impurity is a measure of how often a randomly chosen element from the set would be incorrectly classified. A Gini Impurity of 0 indicates perfect purity (all instances in the node belong to the same class), while a Gini Impurity of 0.5 indicates maximum impurity (the instances are evenly distributed across classes).\n",
        "\n",
        "Formula:\n",
        "Gini\n",
        "(\n",
        "𝑡\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "2\n",
        "Gini(t)=1−∑\n",
        "i=1\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "2\n",
        "​\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of samples in class\n",
        "𝑖\n",
        "i at node\n",
        "𝑡\n",
        "t,\n",
        "𝐶\n",
        "C is the number of classes.\n",
        "Example:\n",
        "\n",
        "If a node has 60% class A and 40% class B, the Gini impurity would be:\n",
        "Gini\n",
        "=\n",
        "1\n",
        "−\n",
        "(\n",
        "0.6\n",
        "2\n",
        "+\n",
        "0.4\n",
        "2\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "(\n",
        "0.36\n",
        "+\n",
        "0.16\n",
        ")\n",
        "=\n",
        "0.48\n",
        "Gini=1−(0.6\n",
        "2\n",
        " +0.4\n",
        "2\n",
        " )=1−(0.36+0.16)=0.48\n",
        "The lower the Gini score, the better, and the algorithm will try to minimize this value when building the tree.\n",
        "\n",
        "2. Entropy (used in Classification)\n",
        "Entropy is another measure of impurity used in decision trees. It is derived from information theory and quantifies the disorder or uncertainty in the node. A node with low entropy indicates that the class distribution is more certain (more \"pure\"), and a node with high entropy indicates more uncertainty (more \"impure\").\n",
        "\n",
        "Formula:\n",
        "Entropy\n",
        "(\n",
        "𝑡\n",
        ")\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "Entropy(t)=−∑\n",
        "i=1\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "i\n",
        "​\n",
        " )\n",
        "\n",
        "Where:\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of samples in class\n",
        "𝑖\n",
        "i at node\n",
        "𝑡\n",
        "t,\n",
        "𝐶\n",
        "C is the number of classes.\n",
        "Example:\n",
        "\n",
        "If a node has 50% class A and 50% class B, the entropy would be:\n",
        "Entropy\n",
        "=\n",
        "−\n",
        "[\n",
        "0.5\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "0.5\n",
        ")\n",
        "+\n",
        "0.5\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "0.5\n",
        ")\n",
        "]\n",
        "=\n",
        "1\n",
        "Entropy=−[0.5log\n",
        "2\n",
        "​\n",
        " (0.5)+0.5log\n",
        "2\n",
        "​\n",
        " (0.5)]=1\n",
        "If the node has 100% class A (no impurity), the entropy would be 0.\n",
        "The decision tree algorithm will split nodes based on the decrease in entropy, aiming to reduce entropy as much as possible.\n",
        "\n",
        "3. Classification Error (used in Classification)\n",
        "The Classification Error is the simplest impurity measure. It is the proportion of misclassified samples in a node.\n",
        " It’s not as commonly used as Gini or Entropy, but it's still a viable option.\n",
        "\n",
        "Formula:\n",
        "Error\n",
        "(\n",
        "𝑡\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "max\n",
        "⁡\n",
        "(\n",
        "𝑝\n",
        "1\n",
        ",\n",
        "𝑝\n",
        "2\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑝\n",
        "𝐶\n",
        ")\n",
        "Error(t)=1−max(p\n",
        "1\n",
        "​\n",
        " ,p\n",
        "2\n",
        "​\n",
        " ,…,p\n",
        "C\n",
        "​\n",
        " )\n",
        "\n",
        "Where:\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of samples in class\n",
        "𝑖\n",
        "i at node\n",
        "𝑡\n",
        "t,\n",
        "𝐶\n",
        "C is the number of classes.\n",
        "For example, if 80% of a node’s samples are from class A, the classification error would be:\n",
        "Error\n",
        "=\n",
        "1\n",
        "−\n",
        "0.8\n",
        "=\n",
        "0.2\n",
        "Error=1−0.8=0.2\n",
        "\n",
        "The goal of the algorithm is to minimize the error at each step.\n",
        "\n",
        "4. Mean Squared Error (MSE) (used in Regression)\n",
        "For regression problems (where the target variable is continuous), Mean Squared Error (MSE) is used to measure impurity.\n",
        " It calculates the average of the squared differences between the predicted values and the actual values. Lower MSE means that the node’s data is more homogeneous and the prediction is more accurate.\n",
        "\n",
        "Formula:\n",
        "MSE\n",
        "(\n",
        "𝑡\n",
        ")\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "(\n",
        "𝑦\n",
        "𝑖\n",
        "−\n",
        "𝑦\n",
        "^\n",
        ")\n",
        "2\n",
        "MSE(t)=\n",
        "n\n",
        "1\n",
        "​\n",
        " ∑\n",
        "i=1\n",
        "n\n",
        "​\n",
        " (y\n",
        "i\n",
        "​\n",
        " −\n",
        "y\n",
        "^\n",
        "​\n",
        " )\n",
        "2\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "𝑦\n",
        "𝑖\n",
        "y\n",
        "i\n",
        "​\n",
        "  is the actual value of the\n",
        "𝑖\n",
        "i-th sample,\n",
        "𝑦\n",
        "^\n",
        "y\n",
        "^\n",
        "​\n",
        "  is the predicted value for that sample,\n",
        "𝑛\n",
        "n is the number of samples in the node.\n",
        "For example, if a node’s predicted value is 5, and the actual values of the data points in the node are 4, 6, and 7, the MSE will be calculated as:\n",
        "\n",
        "MSE\n",
        "=\n",
        "(\n",
        "4\n",
        "−\n",
        "5\n",
        ")\n",
        "2\n",
        "+\n",
        "(\n",
        "6\n",
        "−\n",
        "5\n",
        ")\n",
        "2\n",
        "+\n",
        "(\n",
        "7\n",
        "−\n",
        "5\n",
        ")\n",
        "2\n",
        "3\n",
        "=\n",
        "1\n",
        "+\n",
        "1\n",
        "+\n",
        "4\n",
        "3\n",
        "=\n",
        "2\n",
        "MSE=\n",
        "3\n",
        "(4−5)\n",
        "2\n",
        " +(6−5)\n",
        "2\n",
        " +(7−5)\n",
        "2\n",
        "\n",
        "​\n",
        " =\n",
        "3\n",
        "1+1+4\n",
        "​\n",
        " =2\n",
        "In regression trees, the algorithm aims to minimize this error when splitting nodes.\n",
        "\n",
        "5. Variance Reduction (used in Regression)\n",
        "Another impurity measure for regression is Variance. The goal here is to split the data in a way that reduces the variance within the resulting subsets.\n",
        " Nodes with low variance are considered \"pure,\" and this method is closely related to MSE, as variance is the square of the standard deviation."
      ],
      "metadata": {
        "id": "cGpf-LP0a0SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.what is the mathematical formula for gini impurity?\n",
        "The mathematical formula for Gini Impurity is:\n",
        "\n",
        "Gini\n",
        "(\n",
        "𝑡\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "2\n",
        "Gini(t)=1−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "2\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "𝐶\n",
        "C is the number of classes in the dataset.\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of samples in class\n",
        "𝑖\n",
        "i at node\n",
        "𝑡\n",
        "t (the current node being evaluated).\n",
        "Explanation:\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the probability (or proportion) of a data point in the node belonging to class\n",
        "𝑖\n",
        "i. For example, if there are 100 data points in a node, and 60 belong to class A, then\n",
        "𝑝\n",
        "𝐴\n",
        "=\n",
        "60\n",
        "100\n",
        "=\n",
        "0.6\n",
        "p\n",
        "A\n",
        "​\n",
        " =\n",
        "100\n",
        "60\n",
        "​\n",
        " =0.6.\n",
        "Gini Impurity measures how \"mixed\" the classes are in a node. A Gini Impurity of 0 means the node is pure (all samples in the node are of the same class), and a Gini Impurity of 1 means that the samples are evenly distributed among all classes (maximum impurity).\n",
        "Example:\n",
        "Suppose you have a binary classification problem with classes A and B, and at a particular node, the proportions of A and B are as follows:\n",
        "\n",
        "𝑝\n",
        "𝐴\n",
        "=\n",
        "0.7\n",
        "p\n",
        "A\n",
        "​\n",
        " =0.7 (70% of the samples are class A)\n",
        "𝑝\n",
        "𝐵\n",
        "=\n",
        "0.3\n",
        "p\n",
        "B\n",
        "​\n",
        " =0.3 (30% of the samples are class B)\n",
        "Then, the Gini Impurity would be:\n",
        "\n",
        "Gini\n",
        "=\n",
        "1\n",
        "−\n",
        "(\n",
        "𝑝\n",
        "𝐴\n",
        "2\n",
        "+\n",
        "𝑝\n",
        "𝐵\n",
        "2\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "(\n",
        "0.7\n",
        "2\n",
        "+\n",
        "0.3\n",
        "2\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "(\n",
        "0.49\n",
        "+\n",
        "0.09\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "0.58\n",
        "=\n",
        "0.42\n",
        "Gini=1−(p\n",
        "A\n",
        "2\n",
        "​\n",
        " +p\n",
        "B\n",
        "2\n",
        "​\n",
        " )=1−(0.7\n",
        "2\n",
        " +0.3\n",
        "2\n",
        " )=1−(0.49+0.09)=1−0.58=0.42\n",
        "So, the Gini Impurity for this node is 0.42.\n",
        "\n",
        "The decision tree algorithm will use this formula to evaluate potential splits. It will choose the split that minimizes the Gini Impurity in the child nodes, aiming to increase the homogeneity of the nodes after the split.\n",
        "\n",
        "Let me know if you need further clarification!"
      ],
      "metadata": {
        "id": "7CWsS2UKkHZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4.what is the mathematical formula of entropy?\n",
        "The mathematical formula for Entropy in the context of decision trees (used in classification tasks) is derived from information theory and is used to measure the disorder or uncertainty in a node. The formula for entropy is:\n",
        "\n",
        "Entropy\n",
        "(\n",
        "𝑡\n",
        ")\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "Entropy(t)=−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "i\n",
        "​\n",
        " )\n",
        "Where:\n",
        "\n",
        "𝐶\n",
        "C is the number of classes in the dataset.\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of samples in class\n",
        "𝑖\n",
        "i at node\n",
        "𝑡\n",
        "t (the current node being evaluated).\n",
        "The sum runs over all the classes in the node.\n",
        "Explanation:\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the probability (or proportion) of data points in the node belonging to class\n",
        "𝑖\n",
        "i.\n",
        "Entropy quantifies the uncertainty or randomness in the data. If the classes are perfectly balanced (i.e., no class is dominant), the entropy is higher (more uncertain). If all data points belong to a single class, entropy is 0 (perfectly pure).\n",
        "The logarithm in the formula is base 2, which means the unit of entropy is bits.\n",
        "Example:\n",
        "Suppose you have a binary classification problem with classes A and B. At a particular node, the proportions of class A and class B are as follows:\n",
        "\n",
        "𝑝\n",
        "𝐴\n",
        "=\n",
        "0.5\n",
        "p\n",
        "A\n",
        "​\n",
        " =0.5 (50% of the samples are class A)\n",
        "𝑝\n",
        "𝐵\n",
        "=\n",
        "0.5\n",
        "p\n",
        "B\n",
        "​\n",
        " =0.5 (50% of the samples are class B)\n",
        "Then, the entropy would be calculated as:\n",
        "\n",
        "Entropy\n",
        "=\n",
        "−\n",
        "(\n",
        "𝑝\n",
        "𝐴\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝑝\n",
        "𝐴\n",
        ")\n",
        "+\n",
        "𝑝\n",
        "𝐵\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝑝\n",
        "𝐵\n",
        ")\n",
        ")\n",
        "Entropy=−(p\n",
        "A\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "A\n",
        "​\n",
        " )+p\n",
        "B\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "B\n",
        "​\n",
        " ))\n",
        "Substitute the values of\n",
        "𝑝\n",
        "𝐴\n",
        "p\n",
        "A\n",
        "​\n",
        "  and\n",
        "𝑝\n",
        "𝐵\n",
        "p\n",
        "B\n",
        "​\n",
        " :\n",
        "\n",
        "Entropy\n",
        "=\n",
        "−\n",
        "(\n",
        "0.5\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "0.5\n",
        ")\n",
        "+\n",
        "0.5\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "0.5\n",
        ")\n",
        ")\n",
        "Entropy=−(0.5log\n",
        "2\n",
        "​\n",
        " (0.5)+0.5log\n",
        "2\n",
        "​\n",
        " (0.5))\n",
        "Entropy\n",
        "=\n",
        "−\n",
        "(\n",
        "0.5\n",
        "×\n",
        "(\n",
        "−\n",
        "1\n",
        ")\n",
        "+\n",
        "0.5\n",
        "×\n",
        "(\n",
        "−\n",
        "1\n",
        ")\n",
        ")\n",
        "=\n",
        "−\n",
        "(\n",
        "−\n",
        "1\n",
        ")\n",
        "=\n",
        "1\n",
        "Entropy=−(0.5×(−1)+0.5×(−1))=−(−1)=1\n",
        "So, the entropy for this node is 1, which indicates maximum uncertainty or disorder (i.e., the classes are equally distributed).\n",
        "\n",
        "If the distribution were skewed, such as:\n",
        "\n",
        "𝑝\n",
        "𝐴\n",
        "=\n",
        "0.9\n",
        "p\n",
        "A\n",
        "​\n",
        " =0.9 and\n",
        "𝑝\n",
        "𝐵\n",
        "=\n",
        "0.1\n",
        "p\n",
        "B\n",
        "​\n",
        " =0.1,\n",
        "Then, the entropy would be:\n",
        "\n",
        "Entropy\n",
        "=\n",
        "−\n",
        "(\n",
        "0.9\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "0.9\n",
        ")\n",
        "+\n",
        "0.1\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "0.1\n",
        ")\n",
        ")\n",
        "Entropy=−(0.9log\n",
        "2\n",
        "​\n",
        " (0.9)+0.1log\n",
        "2\n",
        "​\n",
        " (0.1))\n",
        "Entropy\n",
        "≈\n",
        "−\n",
        "(\n",
        "0.9\n",
        "×\n",
        "(\n",
        "−\n",
        "0.137\n",
        ")\n",
        "+\n",
        "0.1\n",
        "×\n",
        "(\n",
        "−\n",
        "3.322\n",
        ")\n",
        ")\n",
        "≈\n",
        "−\n",
        "(\n",
        "−\n",
        "0.1233\n",
        "−\n",
        "0.3322\n",
        ")\n",
        "=\n",
        "0.4555\n",
        "Entropy≈−(0.9×(−0.137)+0.1×(−3.322))≈−(−0.1233−0.3322)=0.4555\n",
        "In this case, the entropy is 0.4555, which is lower, indicating less uncertainty and more dominance of one class.\n",
        "\n",
        "Interpretation:\n",
        "High Entropy: If the classes are evenly distributed, entropy is high (maximum uncertainty).\n",
        "Low Entropy: If one class dominates, entropy is low (pure, less uncertainty).\n",
        "When building a decision tree, the algorithm tries to minimize the entropy by choosing splits that make the child nodes as \"pure\" as possible, i.e., with lower entropy.\n",
        "\n",
        "Let me know if you need further details!"
      ],
      "metadata": {
        "id": "c5gVBcNsFNY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5.what is inormation gain and how it is used in decision trees?\n",
        "Information Gain is a key concept used in decision trees to decide how to split the data at each node. It measures how much uncertainty is reduced (or \"information\" is gained) after splitting the data based on a particular feature. The goal is to choose the feature that provides the highest information gain, meaning it best separates the data into distinct classes (for classification tasks) or values (for regression tasks).\n",
        "\n",
        "Formula for Information Gain:\n",
        "Information Gain (IG) is the difference between the entropy of the original dataset (before the split) and the weighted average entropy of the subsets (after the split).\n",
        "\n",
        "Information Gain\n",
        "(\n",
        "𝑆\n",
        ",\n",
        "𝐴\n",
        ")\n",
        "=\n",
        "Entropy\n",
        "(\n",
        "𝑆\n",
        ")\n",
        "−\n",
        "∑\n",
        "𝑣\n",
        "∈\n",
        "Values\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "∣\n",
        "𝑆\n",
        "𝑣\n",
        "∣\n",
        "∣\n",
        "𝑆\n",
        "∣\n",
        "Entropy\n",
        "(\n",
        "𝑆\n",
        "𝑣\n",
        ")\n",
        "Information Gain(S,A)=Entropy(S)−\n",
        "v∈Values(A)\n",
        "∑\n",
        "​\n",
        "\n",
        "∣S∣\n",
        "∣S\n",
        "v\n",
        "​\n",
        " ∣\n",
        "​\n",
        " Entropy(S\n",
        "v\n",
        "​\n",
        " )\n",
        "Where:\n",
        "\n",
        "𝑆\n",
        "S is the current dataset (or set of instances at the node).\n",
        "𝐴\n",
        "A is the feature being considered for splitting.\n",
        "Values\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "Values(A) is the set of all possible values (or categories) that feature\n",
        "𝐴\n",
        "A can take.\n",
        "𝑆\n",
        "𝑣\n",
        "S\n",
        "v\n",
        "​\n",
        "  is the subset of\n",
        "𝑆\n",
        "S where feature\n",
        "𝐴\n",
        "A takes value\n",
        "𝑣\n",
        "v.\n",
        "∣\n",
        "𝑆\n",
        "∣\n",
        "∣S∣ and\n",
        "∣\n",
        "𝑆\n",
        "𝑣\n",
        "∣\n",
        "∣S\n",
        "v\n",
        "​\n",
        " ∣ are the number of elements in\n",
        "𝑆\n",
        "S and\n",
        "𝑆\n",
        "𝑣\n",
        "S\n",
        "v\n",
        "​\n",
        " , respectively.\n",
        "Entropy\n",
        "(\n",
        "𝑆\n",
        ")\n",
        "Entropy(S) is the entropy of the entire set\n",
        "𝑆\n",
        "S before the split.\n",
        "Entropy\n",
        "(\n",
        "𝑆\n",
        "𝑣\n",
        ")\n",
        "Entropy(S\n",
        "v\n",
        "​\n",
        " ) is the entropy of the subset\n",
        "𝑆\n",
        "𝑣\n",
        "S\n",
        "v\n",
        "​\n",
        "  (the subset where feature\n",
        "𝐴\n",
        "A takes value\n",
        "𝑣\n",
        "v).\n",
        "Steps in Using Information Gain for Splitting:\n",
        "Calculate the Entropy of the Whole Dataset (S): This is the entropy of the original dataset (before the split). It measures the level of uncertainty or disorder in the data.\n",
        "\n",
        "For Each Feature, Calculate the Entropy of the Subsets: For each possible feature\n",
        "𝐴\n",
        "A, you split the dataset into subsets based on the possible values of\n",
        "𝐴\n",
        "A. For each subset\n",
        "𝑆\n",
        "𝑣\n",
        "S\n",
        "v\n",
        "​\n",
        " , calculate the entropy.\n",
        "\n",
        "Calculate the Information Gain: Information Gain for a feature\n",
        "𝐴\n",
        "A is the reduction in entropy after the data is split based on that feature.\n",
        "\n",
        "Choose the Feature with the Highest Information Gain: The decision tree algorithm will choose the feature with the highest information gain to split the data at the current node.\n",
        "\n",
        "Example:\n",
        "Suppose we have a dataset with two classes: Class A and Class B, and we are deciding how to split the data based on a feature, let's say \"Weather\", which can take the values: Sunny, Rainy, and Cloudy.\n",
        "\n",
        "1. Entropy of the Original Dataset (Before the Split):\n",
        "Let's say the original dataset has the following proportions of classes:\n",
        "\n",
        "Class A: 60%\n",
        "Class B: 40%\n",
        "We calculate the entropy of the original dataset (S):\n",
        "\n",
        "Entropy\n",
        "(\n",
        "𝑆\n",
        ")\n",
        "=\n",
        "−\n",
        "(\n",
        "0.6\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "0.6\n",
        ")\n",
        "+\n",
        "0.4\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "0.4\n",
        ")\n",
        ")\n",
        "≈\n",
        "0.971\n",
        "Entropy(S)=−(0.6log\n",
        "2\n",
        "​\n",
        " (0.6)+0.4log\n",
        "2\n",
        "​\n",
        " (0.4))≈0.971\n",
        "2. Entropy of the Subsets (After the Split):\n",
        "Now, let's say after splitting the data based on the Weather feature, we get the following subsets:\n",
        "\n",
        "Sunny: 10 samples, 7 from Class A, 3 from Class B.\n",
        "Rainy: 5 samples, 1 from Class A, 4 from Class B.\n",
        "Cloudy: 5 samples, 4 from Class A, 1 from Class B.\n",
        "We now calculate the entropy for each subset.\n",
        "\n",
        "For Sunny:\n",
        "\n",
        "Entropy\n",
        "(\n",
        "𝑆\n",
        "𝑢\n",
        "𝑛\n",
        "𝑛\n",
        "𝑦\n",
        ")\n",
        "=\n",
        "−\n",
        "(\n",
        "7\n",
        "10\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "7\n",
        "10\n",
        ")\n",
        "+\n",
        "3\n",
        "10\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "3\n",
        "10\n",
        ")\n",
        ")\n",
        "≈\n",
        "0.88\n",
        "Entropy(Sunny)=−(\n",
        "10\n",
        "7\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (\n",
        "10\n",
        "7\n",
        "​\n",
        " )+\n",
        "10\n",
        "3\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (\n",
        "10\n",
        "3\n",
        "​\n",
        " ))≈0.88\n",
        "For Rainy:\n",
        "\n",
        "Entropy\n",
        "(\n",
        "𝑅\n",
        "𝑎\n",
        "𝑖\n",
        "𝑛\n",
        "𝑦\n",
        ")\n",
        "=\n",
        "−\n",
        "(\n",
        "1\n",
        "5\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "1\n",
        "5\n",
        ")\n",
        "+\n",
        "4\n",
        "5\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "4\n",
        "5\n",
        ")\n",
        ")\n",
        "≈\n",
        "0.72\n",
        "Entropy(Rainy)=−(\n",
        "5\n",
        "1\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (\n",
        "5\n",
        "1\n",
        "​\n",
        " )+\n",
        "5\n",
        "4\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (\n",
        "5\n",
        "4\n",
        "​\n",
        " ))≈0.72\n",
        "For Cloudy:\n",
        "\n",
        "Entropy\n",
        "(\n",
        "𝐶\n",
        "𝑙\n",
        "𝑜\n",
        "𝑢\n",
        "𝑑\n",
        "𝑦\n",
        ")\n",
        "=\n",
        "−\n",
        "(\n",
        "4\n",
        "5\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "4\n",
        "5\n",
        ")\n",
        "+\n",
        "1\n",
        "5\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "1\n",
        "5\n",
        ")\n",
        ")\n",
        "≈\n",
        "0.72\n",
        "Entropy(Cloudy)=−(\n",
        "5\n",
        "4\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (\n",
        "5\n",
        "4\n",
        "​\n",
        " )+\n",
        "5\n",
        "1\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (\n",
        "5\n",
        "1\n",
        "​\n",
        " ))≈0.72\n",
        "3. Calculate the Weighted Average Entropy of the Subsets:\n",
        "Now, we calculate the weighted average entropy after the split:\n",
        "\n",
        "Weighted Entropy\n",
        "=\n",
        "10\n",
        "20\n",
        "×\n",
        "0.88\n",
        "+\n",
        "5\n",
        "20\n",
        "×\n",
        "0.72\n",
        "+\n",
        "5\n",
        "20\n",
        "×\n",
        "0.72\n",
        "=\n",
        "0.78\n",
        "Weighted Entropy=\n",
        "20\n",
        "10\n",
        "​\n",
        " ×0.88+\n",
        "20\n",
        "5\n",
        "​\n",
        " ×0.72+\n",
        "20\n",
        "5\n",
        "​\n",
        " ×0.72=0.78\n",
        "4. Calculate Information Gain:\n",
        "Finally, we calculate the information gain for the feature \"Weather\":\n",
        "\n",
        "Information Gain\n",
        "(\n",
        "𝑊\n",
        "𝑒\n",
        "𝑎\n",
        "𝑡\n",
        "ℎ\n",
        "𝑒\n",
        "𝑟\n",
        ")\n",
        "=\n",
        "Entropy\n",
        "(\n",
        "𝑆\n",
        ")\n",
        "−\n",
        "Weighted Entropy\n",
        "=\n",
        "0.971\n",
        "−\n",
        "0.78\n",
        "=\n",
        "0.191\n",
        "Information Gain(Weather)=Entropy(S)−Weighted Entropy=0.971−0.78=0.191\n",
        "This means that by splitting the dataset based on the Weather feature, the uncertainty is reduced by 0.191.\n",
        "\n",
        "Choosing the Best Feature:\n",
        "In a decision tree, the feature with the highest information gain will be chosen for the split. The tree-building process continues recursively, splitting the data based on the feature with the highest information gain at each node, until a stopping criterion is met (e.g., maximum tree depth, or nodes are pure).\n",
        "\n",
        "Why Information Gain is Important:\n",
        "Information Gain measures how much a feature helps in reducing uncertainty or disorder in the data. The more information a feature provides in making predictions, the better it is for the tree.\n",
        "The goal of the decision tree is to maximize the information gain at each node to create a model that makes accurate predictions.\n",
        "Let me know if you need further clarification!"
      ],
      "metadata": {
        "id": "moJWqP-0Ff6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. When should we use Elastic Net instead of Lasso or Ridge?\n",
        "Elastic Net is a regularization technique that combines the strengths of both Lasso and Ridge regression. To understand when to use Elastic Net over Lasso or Ridge, it's helpful to know the key differences between the three methods and their strengths:\n",
        "\n",
        "1. Lasso Regression (L1 Regularization)\n",
        "Lasso (Least Absolute Shrinkage and Selection Operator) applies L1 regularization, which tends to shrink the coefficients of less important features to exactly zero, effectively performing feature selection. This makes it very useful when you believe that only a subset of the features are important for predicting the target.\n",
        "Pros:\n",
        "Can produce sparse models by setting some coefficients to zero (feature selection).\n",
        "Works well when there are a lot of irrelevant features or if you suspect that only a few features are truly predictive.\n",
        "Cons:\n",
        "When features are highly correlated, Lasso might select one feature and ignore the others, even if they carry important information.\n",
        "2. Ridge Regression (L2 Regularization)\n",
        "Ridge applies L2 regularization, which shrinks the coefficients of all features towards zero, but never exactly to zero. This means it doesn’t perform feature selection but helps in situations where we want to reduce the impact of multicollinearity (highly correlated predictors) or prevent overfitting by adding a penalty to large coefficients.\n",
        "Pros:\n",
        "Works well when you have many small/weak features that contribute to the outcome and you don’t want to discard any of them.\n",
        "Less sensitive to multicollinearity since it doesn’t eliminate variables but instead shrinks their coefficients.\n",
        "Cons:\n",
        "Doesn’t perform feature selection (i.e., it doesn't set coefficients exactly to zero).\n",
        "3. Elastic Net (Combination of L1 and L2 Regularization)\n",
        "Elastic Net is a hybrid of Lasso and Ridge, incorporating both L1 and L2 regularization. It’s controlled by two parameters:\n",
        "Alpha: Determines the mix between Lasso (L1) and Ridge (L2). When alpha = 1, it behaves like Lasso, and when alpha = 0, it behaves like Ridge. Values between 0 and 1 combine both L1 and L2 penalties.\n",
        "Lambda: Controls the overall strength of the regularization (how much to penalize the coefficients).\n",
        "Pros:\n",
        "Combines the benefits of both Lasso and Ridge: It performs feature selection (like Lasso) while also handling multicollinearity and situations where features are highly correlated (like Ridge).\n",
        "More robust when you have highly correlated predictors: Lasso may arbitrarily select one feature from a group of correlated ones, but Elastic Net can handle this better by sharing the penalty across correlated features.\n",
        "Cons:\n",
        "It adds another parameter (alpha) to tune, so it may require additional hyperparameter optimization.\n",
        "When to Use Elastic Net instead of Lasso or Ridge:\n",
        "Elastic Net is typically preferred in the following situations:\n",
        "\n",
        "When You Have Many Correlated Features:\n",
        "\n",
        "Lasso might fail to perform well when there are highly correlated features because it will tend to select only one feature and ignore the others (even if all are important). Elastic Net is better at handling correlated predictors because it distributes the penalty across correlated variables and can select multiple features from a group.\n",
        "When You Need Feature Selection and Regularization:\n",
        "\n",
        "If you believe that only a subset of your features are important (like in Lasso), but there might also be correlated predictors that are important, Elastic Net combines the best of both worlds by performing feature selection and handling multicollinearity.\n",
        "When You Have a Large Number of Features:\n",
        "\n",
        "If the number of features is large compared to the number of samples, and you're unsure about which features are relevant, Elastic Net can help to both regularize the model and perform feature selection. Lasso might be too aggressive (leaving out important features), while Ridge might include too many irrelevant features.\n",
        "When Lasso Is Too Aggressive:\n",
        "\n",
        "If you find that Lasso is removing too many features (possibly over-simplifying your model), Elastic Net can provide a softer approach by allowing a mix of L1 and L2 penalties. This can help you retain more relevant features while still applying some regularization.\n",
        "When Ridge Doesn't Lead to Sparse Models:\n",
        "\n",
        "Ridge regularization doesn’t perform feature selection, which could lead to a model with too many features. Elastic Net can give you a balance by setting some coefficients to zero (as in Lasso) and shrinking others (as in Ridge).\n",
        "Key Scenarios for Elastic Net:\n",
        "Large datasets with many features: When you have a high-dimensional feature space (lots of predictors) and you want to perform feature selection while also handling multicollinearity, Elastic Net is a good choice.\n",
        "Presence of correlated features: If the dataset contains highly correlated variables, Elastic Net is typically preferred over Lasso because it handles correlated features better.\n",
        "When you need a balance between Lasso and Ridge: Elastic Net is useful when you want a model that benefits from both Lasso's feature selection and Ridge's handling of multicollinearity.\n",
        "\n"
      ],
      "metadata": {
        "id": "-Gx_znmGOiH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8.What is the impact of the regularization parameter (1) in Logistic Regression?\n",
        "In Logistic Regression, the regularization parameter plays a crucial role in controlling the complexity of the model. Regularization is used to prevent the model from overfitting the training data by penalizing the size of the coefficients. It ensures that the model doesn't become too complex and that it generalizes well to unseen data.\n",
        "\n",
        "The regularization parameter is typically denoted as\n",
        "𝜆\n",
        "λ (or\n",
        "𝐶\n",
        "C in some libraries like scikit-learn, where\n",
        "𝐶\n",
        "=\n",
        "1\n",
        "𝜆\n",
        "C=\n",
        "λ\n",
        "1\n",
        "​\n",
        " ). This parameter controls the strength of the regularization. The impact of the regularization parameter can be understood in terms of L1 (Lasso) or L2 (Ridge) regularization:\n",
        "\n",
        "1. Effect of the Regularization Parameter\n",
        "𝜆\n",
        "λ (or\n",
        "𝐶\n",
        "C):\n",
        "L2 Regularization (Ridge)\n",
        "Ridge regularization adds a penalty on the squared values of the coefficients:\n",
        "\n",
        "Cost Function (with L2 regularization)\n",
        "=\n",
        "Logistic Loss\n",
        "+\n",
        "𝜆\n",
        "∑\n",
        "𝑗\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "𝜃\n",
        "𝑗\n",
        "2\n",
        "Cost Function (with L2 regularization)=Logistic Loss+λ\n",
        "j=1\n",
        "∑\n",
        "n\n",
        "​\n",
        " θ\n",
        "j\n",
        "2\n",
        "​\n",
        "\n",
        "where\n",
        "𝜃\n",
        "𝑗\n",
        "θ\n",
        "j\n",
        "​\n",
        "  represents the coefficients of the model, and\n",
        "𝜆\n",
        "λ is the regularization parameter.\n",
        "\n",
        "Small\n",
        "𝜆\n",
        "λ (Weak Regularization): If\n",
        "𝜆\n",
        "λ is close to 0, the regularization term becomes very small, and the logistic regression behaves similarly to an unregularized model. The coefficients can become large, potentially leading to overfitting (i.e., the model is too complex and fits the noise in the data).\n",
        "\n",
        "Large\n",
        "𝜆\n",
        "λ (Strong Regularization): If\n",
        "𝜆\n",
        "λ is large, the penalty on the coefficients increases. This forces the model to shrink the coefficients towards zero. This reduces the complexity of the model and helps to prevent overfitting. However, if\n",
        "𝜆\n",
        "λ is too large, it can lead to underfitting (i.e., the model is too simple and doesn’t capture the underlying patterns in the data).\n",
        "\n",
        "L1 Regularization (Lasso)\n",
        "Lasso regularization adds a penalty on the absolute values of the coefficients:\n",
        "\n",
        "Cost Function (with L1 regularization)\n",
        "=\n",
        "Logistic Loss\n",
        "+\n",
        "𝜆\n",
        "∑\n",
        "𝑗\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "∣\n",
        "𝜃\n",
        "𝑗\n",
        "∣\n",
        "Cost Function (with L1 regularization)=Logistic Loss+λ\n",
        "j=1\n",
        "∑\n",
        "n\n",
        "​\n",
        " ∣θ\n",
        "j\n",
        "​\n",
        " ∣\n",
        "where\n",
        "𝜆\n",
        "λ is the regularization parameter.\n",
        "\n",
        "Small\n",
        "𝜆\n",
        "λ: If\n",
        "𝜆\n",
        "λ is close to zero, the model behaves like an unregularized logistic regression, allowing coefficients to grow large and possibly overfit the training data.\n",
        "\n",
        "Large\n",
        "𝜆\n",
        "λ: With large\n",
        "𝜆\n",
        "λ, the coefficients are heavily penalized, and some of the coefficients may be shrunk exactly to zero, effectively eliminating certain features (i.e., performing feature selection). If\n",
        "𝜆\n",
        "λ is too large, the model could become too simple, potentially underfitting the data.\n",
        "\n",
        "Elastic Net Regularization\n",
        "Elastic Net regularization combines both L1 and L2 penalties:\n",
        "Cost Function (with Elastic Net regularization)\n",
        "=\n",
        "Logistic Loss\n",
        "+\n",
        "𝜆\n",
        "1\n",
        "∑\n",
        "𝑗\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "∣\n",
        "𝜃\n",
        "𝑗\n",
        "∣\n",
        "+\n",
        "𝜆\n",
        "2\n",
        "∑\n",
        "𝑗\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "𝜃\n",
        "𝑗\n",
        "2\n",
        "Cost Function (with Elastic Net regularization)=Logistic Loss+λ\n",
        "1\n",
        "​\n",
        "\n",
        "j=1\n",
        "∑\n",
        "n\n",
        "​\n",
        " ∣θ\n",
        "j\n",
        "​\n",
        " ∣+λ\n",
        "2\n",
        "​\n",
        "\n",
        "j=1\n",
        "∑\n",
        "n\n",
        "​\n",
        " θ\n",
        "j\n",
        "2\n",
        "​\n",
        "\n",
        "Elastic Net combines the effects of feature selection (from Lasso) and shrinkage (from Ridge). The impact of the regularization parameter is influenced by both\n",
        "𝜆\n",
        "1\n",
        "λ\n",
        "1\n",
        "​\n",
        "  (L1 strength) and\n",
        "𝜆\n",
        "2\n",
        "λ\n",
        "2\n",
        "​\n",
        "  (L2 strength).\n",
        "2. Impact of the Regularization Parameter:\n",
        "Overfitting and Underfitting: The regularization parameter helps balance the tradeoff between underfitting (too simple model) and overfitting (too complex model).\n",
        "\n",
        "A small\n",
        "𝜆\n",
        "λ might lead to overfitting as the model tries to fit noise in the data.\n",
        "A large\n",
        "𝜆\n",
        "λ might lead to underfitting because the model is too simplistic and doesn’t capture the important patterns in the data.\n",
        "Interpretability: A larger regularization parameter (\n",
        "𝜆\n",
        "λ) can also make the model more interpretable because it tends to shrink coefficients to smaller values, and potentially zero, removing less important features. This is especially useful in Lasso regression, where L1 regularization can zero out coefficients and perform automatic feature selection.\n",
        "\n",
        "Model Complexity: The regularization parameter directly influences the complexity of the model:\n",
        "\n",
        "For small\n",
        "𝜆\n",
        "λ: The model has less regularization, and the coefficients can grow large, making the model complex and more prone to overfitting.\n",
        "For large\n",
        "𝜆\n",
        "λ: The model has more regularization, and the coefficients are constrained, which makes the model simpler but possibly underfit.\n",
        "3. Practical Considerations:\n",
        "Hyperparameter Tuning: The value of\n",
        "𝜆\n",
        "λ is typically chosen via cross-validation. You can try a range of values for\n",
        "𝜆\n",
        "λ and select the one that minimizes the validation error.\n",
        "\n",
        "Scale of the Features: Logistic regression with regularization is sensitive to the scale of the features. It's important to normalize or standardize the features before fitting the model. This ensures that the regularization penalizes all features equally."
      ],
      "metadata": {
        "id": "T61ftglVVVdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9. What are the key assumptions of Logistic Regression?\n",
        "Logistic Regression is a widely used classification algorithm, especially for binary classification problems. While it is a powerful and flexible model, it comes with a set of key assumptions that should be considered for the model to perform well. Below are the key assumptions of logistic regression:\n",
        "\n",
        "1. Linear Relationship Between the Independent Variables and the Log-Odds:\n",
        "Assumption: Logistic regression assumes that there is a linear relationship between the independent variables (features) and the log-odds of the dependent variable.\n",
        "Explanation: The model estimates the probability of the outcome using a logistic function, which is a function of a linear combination of the input features. This means that while the relationship between the dependent variable and the independent variables is not linear, the log-odds (the natural logarithm of the odds) of the dependent variable should have a linear relationship with the independent variables.\n",
        "Example: If the log-odds of a binary outcome\n",
        "𝑌\n",
        "Y is related to\n",
        "𝑋\n",
        "1\n",
        "X\n",
        "1\n",
        "​\n",
        "  and\n",
        "𝑋\n",
        "2\n",
        "X\n",
        "2\n",
        "​\n",
        "  through a linear equation, then:\n",
        "logit\n",
        "(\n",
        "𝑃\n",
        "(\n",
        "𝑌\n",
        "=\n",
        "1\n",
        "∣\n",
        "𝑋\n",
        ")\n",
        ")\n",
        "=\n",
        "𝛽\n",
        "0\n",
        "+\n",
        "𝛽\n",
        "1\n",
        "𝑋\n",
        "1\n",
        "+\n",
        "𝛽\n",
        "2\n",
        "𝑋\n",
        "2\n",
        "+\n",
        "⋯\n",
        "+\n",
        "𝛽\n",
        "𝑛\n",
        "𝑋\n",
        "𝑛\n",
        "logit(P(Y=1∣X))=β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " X\n",
        "1\n",
        "​\n",
        " +β\n",
        "2\n",
        "​\n",
        " X\n",
        "2\n",
        "​\n",
        " +⋯+β\n",
        "n\n",
        "​\n",
        " X\n",
        "n\n",
        "​\n",
        "\n",
        "2. Independence of Observations:\n",
        "Assumption: The observations (data points) should be independent of each other.\n",
        "Explanation: Logistic regression assumes that there is no correlation between the observations. This means that the outcome for one data point should not influence or be influenced by the outcome of another data point.\n",
        "Example: This assumption would be violated if the data contains clusters or groups of observations that are correlated, such as when data is collected over time (time series) or from subjects in the same group (e.g., patients from the same clinic).\n",
        "3. No or Little Multicollinearity:\n",
        "Assumption: Logistic regression assumes that the independent variables are not highly correlated with each other.\n",
        "Explanation: If the independent variables (predictors) are highly correlated with each other (i.e., multicollinearity), it can cause problems in estimating the coefficients. Multicollinearity makes it difficult to isolate the individual effect of each variable, leading to unstable and unreliable estimates of the coefficients.\n",
        "How to Check: Multicollinearity can be checked using tools like Variance Inflation Factor (VIF). High VIF values (greater than 10) suggest problematic multicollinearity.\n",
        "4. Binary or Dichotomous Dependent Variable:\n",
        "Assumption: Logistic regression is used for binary classification, where the dependent variable has only two possible outcomes (e.g., success/failure, yes/no, 0/1).\n",
        "Explanation: The dependent variable in logistic regression should be binary (two classes). Logistic regression estimates the probability of one class (typically labeled as 1), and the other class is simply the complement (labeled as 0).\n",
        "Example: Predicting whether an email is spam (1) or not spam (0).\n",
        "5. Large Sample Size:\n",
        "Assumption: Logistic regression performs best with a large sample size.\n",
        "Explanation: Since logistic regression estimates parameters based on Maximum Likelihood Estimation (MLE), it requires a sufficiently large sample size to produce reliable estimates. With smaller datasets, logistic regression might not converge or might provide biased results.\n",
        "Rule of Thumb: A general rule of thumb is that you need at least 10 events per predictor variable (EPV) to ensure a reliable model, where \"events\" refer to the outcome variable (e.g., the number of 1’s in a binary outcome).\n",
        "6. No Strong Outliers:\n",
        "Assumption: Logistic regression assumes that there are no strong outliers in the independent variables.\n",
        "Explanation: Outliers can disproportionately influence the estimates of the coefficients and can lead to misleading results. Logistic regression is sensitive to outliers in the predictor variables, which can distort the decision boundary.\n",
        "How to Check: Outliers can be checked by examining plots like boxplots or by computing the Cook’s Distance.\n",
        "7. Homoscedasticity (or Constant Variance of the Error Terms):\n",
        "Assumption: This assumption is less strict in logistic regression compared to linear regression, but it is still desirable. In logistic regression, we are modeling the probability of an event occurring (i.e., the odds), and it is assumed that the variance of the residuals is roughly constant across all levels of the independent variables.\n",
        "Explanation: In linear regression, the variance of the errors should be constant (homoscedasticity), but in logistic regression, the error terms are distributed according to a Bernoulli distribution. While homoscedasticity is less critical in logistic regression, having extreme variance in the error terms can still cause issues in estimation.\n",
        "8. Additivity:\n",
        "Assumption: Logistic regression assumes that the effects of the predictor variables on the log-odds of the outcome are additive.\n",
        "Explanation: This means that the influence of each predictor variable is added together in the log-odds equation. If interactions or non-linear relationships exist between predictors, these should be explicitly modeled (e.g., by including interaction terms or using non-linear transformations of variables).\n",
        "9. Sufficient Variation in the Outcome Variable:\n",
        "Assumption: There should be sufficient variation in the dependent variable.\n",
        "Explanation: Logistic regression models the log-odds of the outcome. If the dependent variable is very imbalanced (e.g., 95% of the observations belong to one class), it can be difficult for the model to learn the decision boundary. Ideally, the outcome variable should have variation in both classes to allow for meaningful model fitting.\n"
      ],
      "metadata": {
        "id": "bcv1KuAiWOp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10.What are some alternatives to Logistic Regression for classification tasks?\n",
        "Logistic Regression is a popular algorithm for binary and multi-class classification tasks, but it has certain limitations and assumptions that may make it unsuitable for certain problems. Fortunately, there are several alternatives to Logistic Regression that can be more effective depending on the nature of the data, the complexity of the problem, and the assumptions we can make about the data. Here are some of the key alternatives:\n",
        "\n",
        "1. Decision Trees\n",
        "Description: A decision tree is a non-linear classifier that splits the data into subsets based on feature values, creating a tree-like structure with nodes representing feature conditions and leaves representing the predicted class.\n",
        "Advantages:\n",
        "Handles non-linear relationships well.\n",
        "Easy to interpret and visualize.\n",
        "No need for feature scaling.\n",
        "Disadvantages:\n",
        "Prone to overfitting if not pruned properly.\n",
        "Less robust to noisy data.\n",
        "Use when: You have non-linear data, want interpretability, or need a simple model that’s easy to explain.\n",
        "\n",
        "2. Random Forests\n",
        "Description: Random Forest is an ensemble learning method that creates multiple decision trees (bootstrapping), each trained on a different subset of the data. The final classification is based on the majority vote across all the trees.\n",
        "Advantages:\n",
        "Very robust and accurate, even with noisy data.\n",
        "Can handle both numerical and categorical features.\n",
        "Reduces overfitting compared to single decision trees.\n",
        "Disadvantages:\n",
        "Less interpretable than a single decision tree.\n",
        "Computationally expensive for large datasets.\n",
        "Use when: You need a powerful model, can tolerate less interpretability, and want a more robust solution to overfitting.\n",
        "\n",
        "3. Support Vector Machines (SVM)\n",
        "Description: SVM is a powerful classifier that works by finding the hyperplane that maximally separates the data into classes. It is effective in high-dimensional spaces and for cases where there is a clear margin of separation between classes.\n",
        "Advantages:\n",
        "Effective in high-dimensional spaces and with complex boundaries.\n",
        "Works well with both linear and non-linear classification (using kernel functions).\n",
        "Disadvantages:\n",
        "Can be computationally expensive, especially with large datasets.\n",
        "Hard to interpret, especially with non-linear kernels.\n",
        "Use when: You have high-dimensional data, or the data is not linearly separable, and you need a more complex model.\n",
        "\n",
        "4. K-Nearest Neighbors (KNN)\n",
        "Description: KNN is a simple, non-parametric algorithm that classifies a data point based on the majority class of its K nearest neighbors in the feature space.\n",
        "Advantages:\n",
        "Simple and intuitive.\n",
        "No explicit training phase (lazy learning).\n",
        "Works well with multi-class problems.\n",
        "Disadvantages:\n",
        "Computationally expensive at prediction time (especially with large datasets).\n",
        "Sensitive to irrelevant features and requires good feature scaling.\n",
        "Use when: You need a simple model that performs well in cases with a small dataset and where the decision boundary is not necessarily linear.\n",
        "\n",
        "5. Naive Bayes\n",
        "Description: Naive Bayes is a probabilistic classifier based on Bayes' theorem, assuming that the features are conditionally independent given the class label. It calculates the probability of a data point belonging to each class and assigns the class with the highest probability.\n",
        "Advantages:\n",
        "Simple and fast, especially for large datasets.\n",
        "Works well with high-dimensional data (e.g., text classification).\n",
        "Performs well with categorical features.\n",
        "Disadvantages:\n",
        "The independence assumption often doesn't hold in real-world data, making it less accurate in some cases.\n",
        "It may perform poorly when features are correlated.\n",
        "Use when: You have high-dimensional or sparse data, such as in text classification tasks (e.g., spam detection).\n",
        "\n",
        "6. Gradient Boosting Machines (GBM)\n",
        "Description: GBM is an ensemble technique that builds trees sequentially, with each tree trying to correct the errors made by the previous one. Popular variants include XGBoost, LightGBM, and CatBoost.\n",
        "Advantages:\n",
        "Highly accurate and performs well on complex datasets.\n",
        "Robust to overfitting (especially with hyperparameter tuning).\n",
        "Disadvantages:\n",
        "Can be computationally expensive.\n",
        "Harder to interpret than simpler models.\n",
        "Use when: You want a powerful, high-accuracy model and are comfortable with tuning hyperparameters and trade-offs.\n",
        "\n",
        "7. Neural Networks\n",
        "Description: Neural networks, particularly deep learning models, are highly flexible models capable of learning complex relationships in data by using layers of interconnected nodes (neurons).\n",
        "Advantages:\n",
        "Extremely powerful and capable of learning highly complex relationships in data (e.g., image recognition, speech recognition).\n",
        "Can work with large-scale data and high-dimensional feature spaces.\n",
        "Disadvantages:\n",
        "Requires large amounts of data and computational resources.\n",
        "More difficult to interpret than simpler models.\n",
        "Prone to overfitting if not properly tuned or regularized.\n",
        "Use when: You have large amounts of data, complex relationships in your data (such as images or sequences), and computational resources to support deep learning.\n",
        "\n",
        "8. Linear Discriminant Analysis (LDA)\n",
        "Description: LDA is a probabilistic model that assumes the data from each class is drawn from a Gaussian distribution with class-specific means and a shared covariance. It then finds a linear combination of features that best separates the classes.\n",
        "Advantages:\n",
        "Works well when the classes are well-separated and normally distributed.\n",
        "Computationally efficient.\n",
        "Disadvantages:\n",
        "Assumes that the features are normally distributed and that the classes have the same covariance, which may not always hold.\n",
        "Use when: You have a small-to-moderate-sized dataset with features that are approximately normally distributed and want a simple model.\n",
        "\n",
        "9. Artificial Neural Networks (ANN)\n",
        "Description: A generalization of logistic regression that uses layers of neurons to learn complex representations of data. It can handle a variety of tasks including regression and classification.\n",
        "Advantages:\n",
        "Can model complex relationships and interactions between features.\n",
        "Scalable to large datasets.\n",
        "Disadvantages:\n",
        "Computationally intensive, especially for deep architectures.\n",
        "Requires large datasets and careful tuning of hyperparameters.\n",
        "Use when: You have a large, complex dataset and are interested in capturing complex, non-linear relationships.\n",
        "\n",
        "When to Use Alternatives:\n",
        "If the decision boundary is complex and non-linear, decision trees, random forests, SVM, and neural networks may be better alternatives to Logistic Regression.\n",
        "If the data is high-dimensional and you want to perform feature selection, Naive Bayes or SVM might be better choices.\n",
        "If you have tabular data with complex interactions between features, Random Forests or Gradient Boosting Machines are usually the most powerful alternatives.\n",
        "For smaller datasets, KNN, Naive Bayes, or Logistic Regression (with regularization) are often effective.\n",
        "Each of these algorithms has its own strengths and weaknesses, so the choice of the algorithm depends on the nature of your data, the problem you're trying to solve, and the interpretability or accuracy trade-offs you're willing to make.\n",
        "\n",
        "Let me know if you'd like to dive deeper into any of these alternatives!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ypokfZrxbo4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11. What are Classification Evaluation Metrics?\n",
        "Classification evaluation metrics are used to assess the performance of classification models. These metrics help to understand how well a model is predicting the classes (e.g., positive or negative, yes or no) based on the input features. The choice of evaluation metric depends on the specific problem, the type of classification (binary or multi-class), and the balance of classes in the dataset.\n",
        "\n",
        "Here are the key classification evaluation metrics:\n",
        "\n",
        "1. Accuracy\n",
        "Definition: Accuracy is the proportion of correctly predicted instances (both positive and negative) to the total number of instances in the dataset.\n",
        "Formula:\n",
        "Accuracy\n",
        "=\n",
        "True Positives (TP)\n",
        "+\n",
        "True Negatives (TN)\n",
        "Total Samples\n",
        "Accuracy=\n",
        "Total Samples\n",
        "True Positives (TP)+True Negatives (TN)\n",
        "​\n",
        "\n",
        "Use: It's useful when the classes are balanced (i.e., there are roughly equal numbers of instances for each class).\n",
        "Limitations: Accuracy can be misleading when dealing with imbalanced datasets (i.e., one class is much more frequent than the other).\n",
        "2. Precision\n",
        "Definition: Precision (also called Positive Predictive Value) measures the proportion of true positive predictions out of all the predicted positives. It answers the question: Of all the instances that were predicted to be positive, how many were actually positive?\n",
        "Formula:\n",
        "Precision\n",
        "=\n",
        "True Positives (TP)\n",
        "True Positives (TP)\n",
        "+\n",
        "False Positives (FP)\n",
        "Precision=\n",
        "True Positives (TP)+False Positives (FP)\n",
        "True Positives (TP)\n",
        "​\n",
        "\n",
        "Use: Precision is important when the cost of false positives is high (e.g., when predicting whether a person has a disease, and it's critical not to mislabel a healthy person as sick).\n",
        "Limitations: Precision alone doesn't tell you how well the model captures all positives, as it doesn't consider false negatives.\n",
        "3. Recall (Sensitivity or True Positive Rate)\n",
        "Definition: Recall (also called Sensitivity, True Positive Rate) measures the proportion of true positives out of all the actual positives in the dataset. It answers the question: Of all the actual positives, how many did we correctly predict?\n",
        "Formula:\n",
        "Recall\n",
        "=\n",
        "True Positives (TP)\n",
        "True Positives (TP)\n",
        "+\n",
        "False Negatives (FN)\n",
        "Recall=\n",
        "True Positives (TP)+False Negatives (FN)\n",
        "True Positives (TP)\n",
        "​\n",
        "\n",
        "Use: Recall is important when the cost of false negatives is high (e.g., detecting fraud, medical diagnoses, or detecting rare events).\n",
        "Limitations: A model with high recall might have many false positives (low precision), which is why it should be balanced with precision.\n",
        "4. F1-Score\n",
        "Definition: The F1-score is the harmonic mean of precision and recall. It provides a balance between the two metrics, especially when you need to account for both false positives and false negatives.\n",
        "Formula:\n",
        "F1-Score\n",
        "=\n",
        "2\n",
        "×\n",
        "Precision\n",
        "×\n",
        "Recall\n",
        "Precision\n",
        "+\n",
        "Recall\n",
        "F1-Score=2×\n",
        "Precision+Recall\n",
        "Precision×Recall\n",
        "​\n",
        "\n",
        "Use: The F1-score is useful when you want a balance between precision and recall. It's particularly useful when the classes are imbalanced.\n",
        "Limitations: The F1-score may not be sufficient if you need to prioritize precision or recall over the other.\n",
        "5. ROC Curve (Receiver Operating Characteristic Curve)\n",
        "Definition: The ROC curve plots the True Positive Rate (Recall) against the False Positive Rate (FPR) at various thresholds. It shows the trade-off between sensitivity (recall) and specificity across different threshold values.\n",
        "Formula for FPR:\n",
        "False Positive Rate (FPR)\n",
        "=\n",
        "False Positives (FP)\n",
        "False Positives (FP)\n",
        "+\n",
        "True Negatives (TN)\n",
        "False Positive Rate (FPR)=\n",
        "False Positives (FP)+True Negatives (TN)\n",
        "False Positives (FP)\n",
        "​\n",
        "\n",
        "Use: ROC curves are used to evaluate the model's ability to distinguish between the positive and negative classes across different thresholds.\n",
        "Limitations: The ROC curve can be misleading for highly imbalanced datasets, where the model might be biased toward predicting the majority class.\n",
        "6. AUC (Area Under the ROC Curve)\n",
        "Definition: The AUC (Area Under the ROC Curve) is a scalar value that represents the area under the ROC curve. It quantifies the model's ability to distinguish between positive and negative classes, where:\n",
        "AUC = 1: Perfect model.\n",
        "AUC = 0.5: Model performs no better than random chance.\n",
        "Use: AUC is used when you want a single value to assess the model’s overall performance and compare models across different thresholds.\n",
        "Limitations: AUC doesn’t reflect the accuracy of predictions (e.g., it may give a high value for a model that doesn’t make many predictions).\n",
        "7. Confusion Matrix\n",
        "Definition: A confusion matrix is a table that describes the performance of a classification model by showing the actual vs. predicted classifications. It shows:\n",
        "True Positives (TP): Correctly predicted positive instances.\n",
        "True Negatives (TN): Correctly predicted negative instances.\n",
        "False Positives (FP): Incorrectly predicted as positive.\n",
        "False Negatives (FN): Incorrectly predicted as negative.\n",
        "Use: The confusion matrix provides a detailed breakdown of model performance, from which you can derive precision, recall, F1-score, and accuracy.\n",
        "Limitations: While it gives detailed information, it doesn’t summarize the overall performance in one metric (like accuracy or F1-score).\n",
        "8. Specificity (True Negative Rate)\n",
        "Definition: Specificity is the proportion of actual negatives that are correctly identified by the model.\n",
        "Formula:\n",
        "Specificity\n",
        "=\n",
        "True Negatives (TN)\n",
        "True Negatives (TN)\n",
        "+\n",
        "False Positives (FP)\n",
        "Specificity=\n",
        "True Negatives (TN)+False Positives (FP)\n",
        "True Negatives (TN)\n",
        "​\n",
        "\n",
        "Use: Specificity is important when the cost of false positives is high, and you want to avoid incorrectly labeling negatives as positives.\n",
        "Limitations: Specificity alone doesn’t give you a complete picture of how well your model is performing.\n",
        "9. Matthews Correlation Coefficient (MCC)\n",
        "Definition: MCC is a metric that evaluates the quality of binary classifications, considering all four quadrants of the confusion matrix. It takes into account true and false positives and negatives and is considered more informative than accuracy, especially for imbalanced datasets.\n",
        "Formula:\n",
        "MCC\n",
        "=\n",
        "TP\n",
        "×\n",
        "TN\n",
        "−\n",
        "FP\n",
        "×\n",
        "FN\n",
        "(\n",
        "TP\n",
        "+\n",
        "FP\n",
        ")\n",
        "(\n",
        "TP\n",
        "+\n",
        "FN\n",
        ")\n",
        "(\n",
        "TN\n",
        "+\n",
        "FP\n",
        ")\n",
        "(\n",
        "TN\n",
        "+\n",
        "FN\n",
        ")\n",
        "MCC=\n",
        "(TP+FP)(TP+FN)(TN+FP)(TN+FN)\n",
        "​\n",
        "\n",
        "TP×TN−FP×FN\n",
        "​\n",
        "\n",
        "Use: MCC is useful when dealing with imbalanced datasets because it considers both the true positives and true negatives.\n",
        "Limitations: MCC may be difficult to interpret in some cases.\n",
        "10. Log-Loss (Cross-Entropy Loss)\n",
        "Definition: Log-loss measures the performance of a classification model whose output is a probability value between 0 and 1. It penalizes false classifications more severely when the model is confident about the wrong prediction.\n",
        "Formula:\n",
        "Log-Loss\n",
        "=\n",
        "−\n",
        "1\n",
        "𝑁\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑁\n",
        "[\n",
        "𝑦\n",
        "𝑖\n",
        "log\n",
        "⁡\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "+\n",
        "(\n",
        "1\n",
        "−\n",
        "𝑦\n",
        "𝑖\n",
        ")\n",
        "log\n",
        "⁡\n",
        "(\n",
        "1\n",
        "−\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "]\n",
        "Log-Loss=−\n",
        "N\n",
        "1\n",
        "​\n",
        "\n",
        "i=1\n",
        "∑\n",
        "N\n",
        "​\n",
        " [y\n",
        "i\n",
        "​\n",
        " log(p\n",
        "i\n",
        "​\n",
        " )+(1−y\n",
        "i\n",
        "​\n",
        " )log(1−p\n",
        "i\n",
        "​\n",
        " )]\n",
        "Where\n",
        "𝑦\n",
        "𝑖\n",
        "y\n",
        "i\n",
        "​\n",
        "  is the true label and\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the predicted probability.\n",
        "Use: Log-loss is useful when you want to evaluate how close the predicted probabilities are to the true labels. It’s commonly used in classification problems with probability outputs (e.g., in Logistic Regression).\n",
        "Limitations: Log-loss can be misleading if the model is overconfident but incorrect (e.g., predicting 0.99 when the true class is 0).\n",
        "When to Use Which Metric:\n",
        "Accuracy: When the dataset is balanced and you need a simple evaluation metric.\n",
        "Precision: When false positives are costly (e.g., in fraud detection).\n",
        "Recall: When false negatives are costly (e.g., in medical diagnoses).\n",
        "F1-Score: When you need a balance between precision and recall, especially for imbalanced datasets.\n",
        "ROC/AUC: For evaluating classifiers on different thresholds, especially when dealing with imbalanced datasets.\n",
        "Log-Loss: When you need to assess the probability outputs of a model, not just its class predictions.\n",
        "The choice of classification evaluation metric depends on the specific problem, the cost of false positives and false negatives, and whether the dataset is balanced or imbalanced."
      ],
      "metadata": {
        "id": "WW5cCV8FcUxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12. How does class imbalance affect Logistic Regression?\n",
        "Class imbalance refers to a situation where the number of observations in one class is significantly higher than the number of observations in the other class (or classes). In the context of Logistic Regression and other classification algorithms, class imbalance can have several effects that can degrade model performance and lead to misleading results. Here's how class imbalance affects Logistic Regression:\n",
        "\n",
        "1. Bias Toward the Majority Class\n",
        "Effect: Logistic Regression (like many other algorithms) tends to be biased toward the majority class because it aims to minimize the overall error (the likelihood of misclassifications). When one class is dominant, the model can achieve a higher accuracy simply by predicting the majority class more often.\n",
        "Consequence: As a result, the model may fail to identify the minority class effectively, even if it results in a high error rate for that class. The model will essentially \"ignore\" the minority class, leading to poor performance, especially on the minority class.\n",
        "2. Reduced Precision and Recall for the Minority Class\n",
        "Effect: The precision and recall for the minority class can be severely affected. The model may predict the majority class most of the time, leading to:\n",
        "High recall for the majority class (since it correctly identifies most majority-class instances).\n",
        "Low recall for the minority class (since it fails to correctly identify many minority-class instances).\n",
        "Low precision for the minority class (because the few minority-class predictions it makes are likely to be wrong due to the class imbalance).\n",
        "Consequence: If the minority class is crucial (e.g., fraud detection, rare disease prediction), the model may perform poorly in those scenarios.\n",
        "3. Misleading Accuracy\n",
        "Effect: In imbalanced datasets, accuracy can be a misleading metric. For instance, if 95% of the data belongs to the majority class, a model that always predicts the majority class will have an accuracy of 95%, but it won't be useful for detecting the minority class.\n",
        "Consequence: Accuracy becomes less informative in evaluating the true performance of the model, especially when the costs of misclassifying the minority class are high.\n",
        "4. Skewed Decision Boundary\n",
        "Effect: The decision boundary in logistic regression is based on the log-odds of the predicted probabilities. In the case of class imbalance, the model may shift the decision boundary toward the majority class in order to minimize the overall error, which can result in fewer predictions for the minority class.\n",
        "Consequence: The minority class may end up being underrepresented in the predictions, leading to poor classification performance for that class.\n",
        "5. Underfitting the Minority Class\n",
        "Effect: Logistic regression typically tries to find the best-fitting line (or hyperplane) that separates the classes. With imbalanced data, the model might underfit the minority class because it doesn't have enough data points to make accurate predictions for it.\n",
        "Consequence: The model may fail to capture the key characteristics of the minority class, leading to a high false negative rate for that class.\n",
        "How to Handle Class Imbalance in Logistic Regression\n",
        "To mitigate the negative effects of class imbalance, here are several strategies:\n",
        "\n",
        "1. Resampling Techniques\n",
        "Oversampling the Minority Class: Duplicate or generate synthetic samples of the minority class to balance the dataset. SMOTE (Synthetic Minority Over-sampling Technique) is a popular method to generate synthetic data points.\n",
        "Undersampling the Majority Class: Reduce the number of majority class samples to balance the dataset.\n",
        "Note: Resampling can help, but it can also introduce issues like overfitting (in case of oversampling) or loss of valuable information (in case of undersampling).\n",
        "2. Use Class Weights\n",
        "Weighted Logistic Regression: Logistic regression in libraries like scikit-learn allows you to assign different weights to classes using the class_weight parameter. By assigning higher weights to the minority class, the model will penalize misclassifications of the minority class more, encouraging it to make more accurate predictions for the minority class.\n",
        "Formula:\n",
        "Weighted Loss\n",
        "=\n",
        "∑\n",
        "class weight\n",
        "×\n",
        "loss function\n",
        "Weighted Loss=∑class weight×loss function\n",
        "Use case: This is particularly useful when you want to avoid changing the dataset and prefer a more balanced emphasis on both classes during training.\n",
        "3. Adjust the Decision Threshold\n",
        "Effect: Logistic regression outputs a probability (from 0 to 1) for each prediction. The default decision threshold is 0.5, meaning if the probability of a class is greater than 0.5, the prediction will be assigned to the positive class. However, in imbalanced datasets, this threshold can be adjusted to give more weight to the minority class (e.g., using a threshold of 0.3 instead of 0.5 for the positive class).\n",
        "How: Adjusting the decision threshold can help improve recall for the minority class without affecting precision too much. This can be done by examining the precision-recall curve or ROC curve.\n",
        "4. Use Alternative Evaluation Metrics\n",
        "Precision-Recall Curve: Since accuracy is not reliable in imbalanced datasets, precision-recall curves or F1-score are better metrics to evaluate the model, especially for the minority class.\n",
        "ROC-AUC and Precision-Recall AUC: The AUC-ROC or AUC-PR (area under the precision-recall curve) can help evaluate the model's ability to distinguish between classes without relying on accuracy.\n",
        "5. Ensemble Methods\n",
        "Random Forest and Gradient Boosting: Ensemble methods like Random Forest and Gradient Boosting Machines (e.g., XGBoost, LightGBM) are more robust to class imbalance because they combine multiple models and reduce the bias towards the majority class.\n",
        "Use case: If Logistic Regression fails to perform well in an imbalanced dataset, these ensemble methods may provide better results."
      ],
      "metadata": {
        "id": "durkAdVpc5Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13. What is Hyperparameter Tuning in Logistic Regression?\n",
        "Hyperparameter Tuning in Logistic Regression\n",
        "Hyperparameter tuning refers to the process of selecting the best set of hyperparameters for a machine learning model to optimize its performance. In the case of Logistic Regression, hyperparameters are the parameters that are set before training the model and are not learned from the data. These parameters control the learning process and have a significant impact on the model's ability to generalize and make accurate predictions.\n",
        "\n",
        "Key Hyperparameters in Logistic Regression\n",
        "Below are the most important hyperparameters in Logistic Regression that you can tune:\n",
        "\n",
        "1. Regularization Strength (C)\n",
        "Definition: The regularization strength controls the amount of regularization applied to the model. Regularization helps prevent overfitting by adding a penalty to the model's complexity.\n",
        "Explanation:\n",
        "The regularization term in logistic regression is controlled by the hyperparameter C. A high value of C corresponds to low regularization, and a low value of C corresponds to high regularization.\n",
        "Higher values of C: The model becomes more complex and fits the training data more closely (lower regularization), which may lead to overfitting.\n",
        "Lower values of C: The model is constrained more strongly (higher regularization), which helps prevent overfitting but may lead to underfitting if too high.\n",
        "Range: Typically, you choose values in the range [0.01, 1000], depending on the dataset.\n",
        "2. Regularization Type (penalty)\n",
        "Definition: Logistic Regression models can use different types of regularization:\n",
        "'l1' (Lasso): L1 regularization encourages sparsity, meaning it can drive some coefficients to zero, effectively performing feature selection.\n",
        "'l2' (Ridge): L2 regularization helps prevent large weights by penalizing the sum of the squares of the coefficients. It is the most common choice for logistic regression.\n",
        "'elasticnet': A combination of L1 and L2 regularization, offering flexibility to balance between the two regularization types.\n",
        "Explanation:\n",
        "L1 regularization (Lasso) is useful if you believe many features are irrelevant and would like to eliminate some of them.\n",
        "L2 regularization (Ridge) is typically preferred when most of the features are believed to be useful and you just want to prevent overfitting by shrinking the coefficients.\n",
        "3. Solver (solver)\n",
        "Definition: The solver is the algorithm used to optimize the logistic regression model. Different solvers are used for fitting the model depending on the data and regularization type.\n",
        "Available Solvers:\n",
        "'liblinear': A good choice for small datasets and when using L1 regularization. It uses a coordinate descent algorithm.\n",
        "'newton-cg': Suitable for larger datasets and works well with L2 regularization.\n",
        "'lbfgs': A quasi-Newton method, commonly used for larger datasets with L2 regularization.\n",
        "'saga': An efficient solver for large datasets, works well for both L1 and L2 regularization, and is often used when the dataset is sparse.\n",
        "Explanation: The choice of solver can influence the model’s convergence speed and the final solution. The default solver is usually sufficient, but trying different solvers may improve performance for specific datasets.\n",
        "4. Maximum Number of Iterations (max_iter)\n",
        "Definition: This parameter controls the maximum number of iterations the optimization algorithm will run before it stops.\n",
        "Explanation: The optimization algorithm iterates to find the best fit for the logistic regression model. If the model hasn't converged after the specified number of iterations, the solver stops. If convergence is not achieved, you may need to increase max_iter.\n",
        "Typical Values: The default is usually 100, but for large datasets or complex models, this may need to be increased (e.g., 500 or 1000).\n",
        "5. Tolerance (tol)\n",
        "Definition: The tolerance is the stopping criterion for the optimization algorithm. The algorithm stops when the improvement between iterations is smaller than this value.\n",
        "Explanation: A lower tolerance can make the algorithm stop when the model’s coefficients are close to the optimal values. If you want the model to converge more precisely, you can lower the tol value. However, lowering the tolerance can increase computation time.\n",
        "6. Intercept Scaling (intercept_scaling)\n",
        "Definition: This parameter is used when the solver is liblinear. It scales the intercept term. It is useful when you're using a regularization that also applies to the intercept term (L1 or L2).\n",
        "Explanation: In most cases, you won't need to adjust this parameter, but it's there to help if you're dealing with specific situations, such as sparse data.\n",
        "How to Tune Hyperparameters\n",
        "The hyperparameters mentioned above can be tuned using various methods. The most common techniques are:\n",
        "\n",
        "1. Grid Search\n",
        "Explanation: Grid search is an exhaustive search over a specified hyperparameter space. It evaluates all possible combinations of hyperparameters and selects the one with the best performance based on a chosen evaluation metric (e.g., accuracy, F1-score, etc.).\n",
        "2. Random Search\n",
        "Explanation: Instead of evaluating all possible combinations like grid search, random search randomly samples combinations of hyperparameters and evaluates them.\n",
        "Advantage: It's computationally less expensive and can still find good results, especially when the hyperparameter space is large.\n",
        "Implementation:\n",
        "Similar to grid search, but instead of specifying a fixed grid, you specify ranges or distributions from which hyperparameters are randomly selected.\n",
        "3. Bayesian Optimization\n",
        "Explanation: Bayesian optimization is a probabilistic model-based optimization technique. It builds a model of the objective function and uses this model to make more informed decisions about which hyperparameters to evaluate next.\n",
        "Advantages: It is more efficient than grid and random search and can find optimal hyperparameters with fewer evaluations.\n"
      ],
      "metadata": {
        "id": "iZa2U8Z_dMgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14.What are different solvers in Logistic Regression? Which one should be used?\n",
        "Solvers in Logistic Regression\n",
        "In Logistic Regression, the solver is the algorithm used to optimize the cost function and find the best parameters (weights and intercept). Different solvers use different optimization techniques, and the choice of solver can affect both the model's performance and the computation time, depending on the dataset's size and characteristics.\n",
        "\n",
        "Here are the primary solvers available in Logistic Regression:\n",
        "\n",
        "1. liblinear\n",
        "Optimization Algorithm: Coordinate Descent (for L1 regularization) and Newton’s Method (for L2 regularization).\n",
        "Best for:\n",
        "Small datasets.\n",
        "Datasets with a small number of features (sparse or not).\n",
        "L1 regularization (Lasso).\n",
        "Pros:\n",
        "It works well for L1 regularization, which performs feature selection by setting some coefficients to zero.\n",
        "Can be used for small to medium datasets.\n",
        "Cons:\n",
        "Slower for larger datasets compared to other solvers like saga or lbfgs.\n",
        "Use When: You have small datasets or datasets with L1 regularization (i.e., feature selection) and you need exact coefficients for those features.\n",
        "2. lbfgs\n",
        "Optimization Algorithm: Limited-memory Broyden–Fletcher–Goldfarb–Shanno (L-BFGS), an approximation of Newton’s method that uses limited memory.\n",
        "Best for:\n",
        "Large datasets.\n",
        "Datasets where L2 regularization (Ridge) is preferred.\n",
        "When you don't need sparse coefficients.\n",
        "Pros:\n",
        "Efficient for L2 regularization.\n",
        "Works well with large datasets (both in terms of data points and features).\n",
        "Faster convergence than liblinear for large datasets.\n",
        "Cons:\n",
        "Does not handle L1 regularization as efficiently (use liblinear for that).\n",
        "Use When: You have a large dataset and are using L2 regularization (Ridge), as it converges faster and is more efficient for larger problems.\n",
        "3. newton-cg\n",
        "Optimization Algorithm: Newton’s Conjugate Gradient method.\n",
        "Best for:\n",
        "L2 regularization (Ridge).\n",
        "Medium-to-large datasets.\n",
        "Problems where you need fast convergence without requiring too much memory.\n",
        "Pros:\n",
        "Good for large datasets with L2 regularization.\n",
        "Efficient when the number of features is large.\n",
        "Cons:\n",
        "May not be as efficient for L1 regularization.\n",
        "Requires more memory than lbfgs, especially for very large datasets.\n",
        "Use When: You have a larger dataset, and you are using L2 regularization. It converges faster than lbfgs when the dataset is large and dense.\n",
        "4. saga\n",
        "Optimization Algorithm: Stochastic Average Gradient.\n",
        "Best for:\n",
        "Large datasets.\n",
        "Datasets with sparse features (many zero values).\n",
        "Both L1 and L2 regularization.\n",
        "Pros:\n",
        "Efficient for both L1 and L2 regularization.\n",
        "Handles large datasets well and is efficient with sparse datasets.\n",
        "Typically faster than newton-cg and lbfgs for large datasets.\n",
        "Cons:\n",
        "May be slower for small datasets.\n",
        "Can be noisy since it's a stochastic optimization method (but the randomness usually averages out).\n",
        "Use When: You have large datasets, sparse data, or require a solver that handles both L1 and L2 regularization. It is often the best choice for high-dimensional datasets and large sparse matrices.\n"
      ],
      "metadata": {
        "id": "ygwUK68Odgjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15. How is Logistic Regression extended for multiclass classification?\n",
        "In Logistic Regression, the standard model is designed for binary classification, where the output is one of two possible classes. However, in many real-world problems, you may encounter multiclass classification tasks, where the goal is to classify input data into one of several possible classes. Logistic Regression can be extended to handle multiclass classification using two primary techniques: One-vs-Rest (OvR) and Softmax Regression.\n",
        "\n",
        "1. One-vs-Rest (OvR) or One-vs-All (OvA)\n",
        "In the One-vs-Rest (OvR) approach, a separate binary logistic regression classifier is trained for each class. The idea is to treat each class as the positive class and the remaining classes as the negative class in a binary classification problem.\n",
        "\n",
        "How It Works:\n",
        "For K classes, you train K separate binary classifiers.\n",
        "Each classifier\n",
        "𝐶\n",
        "𝑖\n",
        "C\n",
        "i\n",
        "​\n",
        "  is trained to distinguish class\n",
        "𝑖\n",
        "i from all other classes. This means the classifier will output a probability of the sample belonging to class\n",
        "𝑖\n",
        "i.\n",
        "For each class, the logistic regression model will produce a probability of the input being in that class.\n",
        "After training, during prediction, the class with the highest probability is chosen as the predicted class.\n",
        "Example:\n",
        "If you have a dataset with 3 classes (Class 1, Class 2, and Class 3), you would train three logistic regression classifiers:\n",
        "Classifier 1: Class 1 vs. (Class 2 and Class 3)\n",
        "Classifier 2: Class 2 vs. (Class 1 and Class 3)\n",
        "Classifier 3: Class 3 vs. (Class 1 and Class 2)\n",
        "During prediction, the class with the highest probability across the three classifiers will be selected.\n",
        "\n",
        "Pros:\n",
        "Simple to implement.\n",
        "Works well when classes are distinct and not highly imbalanced.\n",
        "Cons:\n",
        "Inefficient: Training K models for K classes increases computational cost, especially for large datasets.\n",
        "Potentially Confusing Decisions: If the classifiers do not agree, it can be challenging to make a decision.\n",
        "Implementation in Scikit-learn:\n",
        "In Scikit-learn, LogisticRegression by default uses the One-vs-Rest (OvR) approach for multiclass classification. You don't need to specify anything extra; it's handled automatically.\n",
        "2. Softmax Regression (Multinomial Logistic Regression)\n",
        "The Softmax Regression approach, also known as Multinomial Logistic Regression, is a generalization of binary logistic regression for multiclass problems. Instead of training separate classifiers, Softmax Regression directly computes probabilities for all classes at once using a single model.\n",
        "\n",
        "How It Works:\n",
        "In Softmax Regression, you have one set of weights for each class. The model outputs a vector of K values (one for each class).\n",
        "The Softmax function is applied to these values to convert them into a valid probability distribution, where the sum of all probabilities is 1.\n",
        "The predicted class is the one with the highest probability.\n",
        "The Softmax function is used to normalize the raw outputs of the model (the scores for each class) into probabilities:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝑦\n",
        "=\n",
        "𝑗\n",
        "∣\n",
        "𝑥\n",
        ")\n",
        "=\n",
        "𝑒\n",
        "𝑧\n",
        "𝑗\n",
        "∑\n",
        "𝑘\n",
        "=\n",
        "1\n",
        "𝐾\n",
        "𝑒\n",
        "𝑧\n",
        "𝑘\n",
        "P(y=j∣x)=\n",
        "∑\n",
        "k=1\n",
        "K\n",
        "​\n",
        " e\n",
        "z\n",
        "k\n",
        "​\n",
        "\n",
        "\n",
        "e\n",
        "z\n",
        "j\n",
        "​\n",
        "\n",
        "\n",
        "​\n",
        "\n",
        "where:\n",
        "\n",
        "𝑧\n",
        "𝑗\n",
        "z\n",
        "j\n",
        "​\n",
        "  is the raw score (logit) for class\n",
        "𝑗\n",
        "j,\n",
        "𝑒\n",
        "𝑧\n",
        "𝑗\n",
        "e\n",
        "z\n",
        "j\n",
        "​\n",
        "\n",
        "  is the exponentiation of the score for class\n",
        "𝑗\n",
        "j,\n",
        "The denominator is the sum of the exponentiated scores for all classes\n",
        "𝐾\n",
        "K.\n",
        "Each class has its own set of weights, and the model computes the probability of each class given the input data, then selects the class with the highest probability.\n",
        "\n",
        "Pros:\n",
        "More efficient than OvR because it only requires one model instead of K separate classifiers.\n",
        "Avoids the potential conflict where OvR classifiers might disagree.\n",
        "Cons:\n",
        "May not perform well when the classes are imbalanced.\n",
        "Requires the entire class set to be available during training, so the model is limited to predicting only the classes it has seen during training.\n",
        "Implementation in Scikit-learn:\n",
        "In Scikit-learn, Softmax Regression can be implemented by setting multi_class='multinomial' when creating the LogisticRegression model.\n",
        "When to Use Each Approach:\n",
        "One-vs-Rest (OvR) is a good choice when:\n",
        "\n",
        "You have relatively few classes.\n",
        "You want simplicity and interpretability.\n",
        "Classes are not highly imbalanced.\n",
        "You are using L1 regularization (since OvR handles L1 regularization well).\n",
        "Softmax Regression (Multinomial Logistic Regression) is better when:\n",
        "\n",
        "You have many classes or a large number of features.\n",
        "You want a more efficient model (one classifier instead of multiple classifiers).\n",
        "You are working with dense data.\n",
        "You need to avoid the conflict of classifiers disagreeing (as in OvR)."
      ],
      "metadata": {
        "id": "9DwPVrSwnMJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16. What are the advantages and disadvantages of Logistic Regression?\n",
        "Advantages and Disadvantages of Logistic Regression\n",
        "Logistic Regression is one of the most commonly used algorithms for binary classification tasks. However, like all algorithms, it has its strengths and weaknesses. Below are the key advantages and disadvantages of Logistic Regression.\n",
        "\n",
        "Advantages of Logistic Regression\n",
        "Simple and Interpretable:\n",
        "\n",
        "Logistic Regression is easy to understand and implement. The model provides a clear interpretation of the relationship between features and the predicted class through the coefficients (weights).\n",
        "The coefficients of the model tell you how much each feature contributes to the prediction of the class. A positive coefficient means that as the feature increases, the probability of the positive class increases, and vice versa for negative coefficients.\n",
        "Efficient:\n",
        "\n",
        "Logistic Regression is computationally efficient. The algorithm is fast to train and works well with smaller datasets or datasets with a relatively low number of features.\n",
        "It can be trained relatively quickly, even on large datasets, because the optimization algorithm is not very complex.\n",
        "Probabilistic Output:\n",
        "\n",
        "Unlike some other classification algorithms (e.g., Support Vector Machines, Decision Trees), Logistic Regression gives a probability score for the predicted class, which can be useful for ranking predictions or when you need to make decisions based on uncertainty.\n",
        "Works Well with Linearly Separable Data:\n",
        "\n",
        "Logistic Regression is particularly effective when the data is linearly separable or nearly linearly separable.\n",
        "It is a good choice when the classes in the dataset can be separated by a straight line or a hyperplane in the feature space.\n",
        "Can Be Regularized:\n",
        "\n",
        "Logistic Regression can be regularized (L1 or L2) to prevent overfitting. Regularization can help the model generalize better by penalizing large weights and reducing complexity.\n",
        "L1 regularization (Lasso) can also perform feature selection by driving some feature coefficients to zero.\n",
        "Less Prone to Overfitting:\n",
        "\n",
        "Logistic Regression, especially when regularized, tends to be less prone to overfitting compared to more complex models like Decision Trees, especially when the number of features is large.\n",
        "Multiclass Classification:\n",
        "\n",
        "Logistic Regression can be extended to multiclass classification problems using techniques like One-vs-Rest (OvR) or Softmax Regression (Multinomial Logistic Regression).\n",
        "Works Well for Probabilistic Interpretation:\n",
        "\n",
        "Logistic Regression is widely used when the goal is to estimate probabilities and not just predict labels. For example, predicting the likelihood of an event occurring (like the probability of a customer purchasing a product).\n",
        "Disadvantages of Logistic Regression\n",
        "Linear Decision Boundaries:\n",
        "\n",
        "Logistic Regression assumes that the relationship between the input features and the output class is linear.\n",
        "If the true relationship is nonlinear, logistic regression may struggle to make accurate predictions unless feature engineering or polynomial features are added.\n",
        "Sensitive to Outliers:\n",
        "\n",
        "Logistic Regression is sensitive to outliers, which can heavily influence the model and lead to suboptimal predictions. Outliers can distort the estimates of the coefficients, especially in small datasets.\n",
        "Outliers can affect the estimated probabilities, making the model less reliable in those cases.\n",
        "Requires Feature Engineering for Complex Relationships:\n",
        "\n",
        "If the data has complex, nonlinear relationships, Logistic Regression alone might not work well unless you transform the features or add interactions. For example, polynomial terms or kernel methods (like SVM with kernels) are needed for capturing nonlinear relationships.\n",
        "The model might require domain expertise to create the right features to capture those complex relationships.\n",
        "Multicollinearity:\n",
        "\n",
        "Logistic Regression assumes that the input features are independent of each other. If there is multicollinearity (i.e., when some features are highly correlated with each other), it can lead to unstable estimates of coefficients and affect the interpretability and accuracy of the model.\n",
        "Regularization (L1 or L2) can help mitigate this issue, but it is something to be mindful of.\n",
        "Not Suitable for Complex Relationships:\n",
        "\n",
        "For more complex tasks or datasets with highly complex feature interactions (such as images, time series, or text), models like Random Forests, Gradient Boosting Machines, or Neural Networks may outperform Logistic Regression.\n",
        "It is not suitable for problems where data has a high degree of interaction between features that cannot be captured by linear terms.\n",
        "Limited to Binary or Multiclass Classification:\n",
        "\n",
        "Logistic Regression is primarily used for classification tasks. For regression tasks, other models like Linear Regression or Support Vector Regression are preferred.\n",
        "It is not inherently suited for tasks like clustering or regression without modification.\n",
        "Assumption of Independence of Features:\n",
        "\n",
        "Logistic Regression assumes that all the input features are independent of one another, which may not always be the case in real-world datasets.\n",
        "This assumption, if violated, can reduce the model’s performance.\n",
        "Overfitting on Complex Data:\n",
        "\n",
        "Logistic Regression may overfit if the model is not properly regularized or if there are too many features relative to the number of training samples, especially in cases where the data is not linearly separable.\n",
        "When to Use Logistic Regression:\n",
        "When the problem is linearly separable or approximately so.\n",
        "When you need probabilistic interpretation (i.e., class probabilities).\n",
        "When your data is not too complex, and you don't expect highly complex relationships between features.\n",
        "When you need a model that is simple and interpretable, with clear decision boundaries.\n",
        "When you have relatively few features, and regularization can help prevent overfitting."
      ],
      "metadata": {
        "id": "taQHJcRyp302"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#17. What are some use cases of Logistic Regression?\n",
        "Use Cases of Logistic Regression\n",
        "Logistic Regression is a versatile and widely-used algorithm, particularly for classification problems where the goal is to predict a categorical outcome. Below are several common use cases where Logistic Regression is frequently applied:\n",
        "\n",
        "1. Medical Diagnosis (Binary Classification)\n",
        "Example: Predicting Disease Presence (e.g., Diabetes, Cancer)\n",
        "Problem: Predicting whether a patient has a certain disease based on medical features (e.g., age, blood pressure, BMI, cholesterol level).\n",
        "Logistic Regression Use: A logistic regression model can be used to predict the probability of a patient having a particular disease, such as predicting the likelihood of a patient developing diabetes or having cancer based on input features.\n",
        "Output: The model provides a probability score that a patient falls into a specific category (e.g., \"1\" for diseased, \"0\" for healthy).\n",
        "2. Email Spam Classification (Binary Classification)\n",
        "Example: Classifying Emails as Spam or Not Spam\n",
        "Problem: Classifying incoming emails as spam or non-spam based on email content and metadata (e.g., subject, sender, body text).\n",
        "Logistic Regression Use: Logistic regression can predict the likelihood that an email is spam or not spam (binary classification).\n",
        "Output: A binary outcome where the model predicts either spam (1) or not spam (0).\n",
        "3. Customer Churn Prediction (Binary Classification)\n",
        "Example: Predicting whether a customer will cancel a subscription or service\n",
        "Problem: Companies want to predict whether a customer will churn (leave) or stay based on customer behavior and demographic data.\n",
        "Logistic Regression Use: Logistic regression can be used to estimate the probability that a customer will churn based on features like customer demographics, account age, usage patterns, etc.\n",
        "Output: A probability value indicating the likelihood of a customer leaving the service, which can be converted into a binary outcome: churn (1) or stay (0).\n",
        "4. Credit Scoring (Binary Classification)\n",
        "Example: Predicting Loan Default (Default or No Default)\n",
        "Problem: Banks and financial institutions use credit scoring models to predict whether a borrower will default on a loan.\n",
        "Logistic Regression Use: By analyzing financial history, income, loan amount, and other features, logistic regression can estimate the probability that a borrower will default on a loan.\n",
        "Output: A binary prediction of default (1) or no default (0).\n",
        "5. Marketing Campaign Effectiveness (Binary Classification)\n",
        "Example: Predicting Customer Response to a Marketing Campaign\n",
        "Problem: Marketers want to predict whether a customer will respond to a specific marketing campaign or not.\n",
        "Logistic Regression Use: The model can predict whether a customer will engage with an offer based on previous purchasing behavior, demographic information, and campaign characteristics.\n",
        "Output: A probability that a customer will respond to a marketing campaign (binary classification: yes (1) or no (0)).\n",
        "6. Fraud Detection (Binary Classification)\n",
        "Example: Detecting Fraudulent Transactions\n",
        "Problem: In financial services, companies need to detect whether a transaction is fraudulent or legitimate.\n",
        "Logistic Regression Use: Based on features like transaction amount, location, merchant details, and time of transaction, logistic regression can predict the likelihood of a transaction being fraudulent.\n",
        "Output: A binary classification, where the model predicts fraud (1) or no fraud (0).\n",
        "7. Disease Risk Prediction (Binary Classification)\n",
        "Example: Predicting the Risk of Heart Disease\n",
        "Problem: Predicting the likelihood that a person will experience a specific health event, such as a heart attack or stroke.\n",
        "Logistic Regression Use: The model can use demographic and medical data (age, cholesterol level, blood pressure, etc.) to predict the risk of heart disease or other conditions.\n",
        "Output: A probability score indicating the likelihood of the health event, which can be used to classify individuals into risk categories (e.g., high risk or low risk).\n",
        "8. Social Media Sentiment Analysis (Binary Classification)\n",
        "Example: Predicting Sentiment of Social Media Posts (Positive or Negative Sentiment)\n",
        "Problem: Classifying social media posts or reviews as positive or negative sentiment based on text analysis.\n",
        "Logistic Regression Use: By analyzing the text content, logistic regression can predict the sentiment of a post, whether it’s favorable or unfavorable.\n",
        "Output: A binary output where the post is classified as positive (1) or negative (0).\n",
        "9. Product Recommendation Systems (Multiclass Classification)\n",
        "Example: Predicting Product Preferences\n",
        "Problem: Predicting the likelihood that a customer will purchase a specific product or category of products.\n",
        "Logistic Regression Use: Logistic regression can be extended to multiclass classification to predict which category of products a user is most likely to buy.\n",
        "Output: Multiple class labels, such as product categories (e.g., electronics, fashion, groceries).\n",
        "10. Political Election Outcome Prediction (Binary or Multiclass Classification)\n",
        "Example: Predicting Election Results (Winner or Loser, Multiple Candidates)\n",
        "Problem: Predicting the outcome of elections based on factors like polling data, demographic features, and historical voting patterns.\n",
        "Logistic Regression Use: For binary classification (e.g., win or lose) or for multiclass (e.g., multiple candidates in a race), logistic regression can predict the likelihood of a candidate winning.\n",
        "Output: A binary or multiclass output indicating the likelihood of winning or predicting the most likely winner.\n",
        "11. Employee Performance Evaluation (Binary or Multiclass Classification)\n",
        "Example: Predicting Employee Performance (High vs. Low Performance, Multiple Ratings)\n",
        "Problem: Predicting the performance of employees based on historical performance data, demographics, and work behavior.\n",
        "Logistic Regression Use: Logistic regression can predict whether an employee is likely to fall into a high-performance or low-performance category, or a multiclass evaluation of performance (e.g., excellent, good, average, poor).\n",
        "Output: Binary or multiclass performance categories.\n",
        "12. Predicting Customer Lifetime Value (CLV) (Regression)\n",
        "Example: Estimating the Value of a Customer to a Business\n",
        "Problem: Logistic Regression can be adapted to predict whether a customer will be highly valuable over their lifetime based on transactional data and customer behavior.\n",
        "Logistic Regression Use: It helps predict if a customer will fall into a high-value category, providing insights into targeting strategies for marketing campaigns.\n",
        "Output: Binary classification: high-value (1) or low-value (0) customer.\n"
      ],
      "metadata": {
        "id": "pqTMg2JJqJIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18. What is the difference between Softmax Regression and Logistic Regression?\n",
        "Difference Between Softmax Regression and Logistic Regression\n",
        "Both Logistic Regression and Softmax Regression are used for classification tasks, but they differ in the type of problems they solve, the output they produce, and how they handle multiple classes. Below is a detailed breakdown of the differences between Softmax Regression and Logistic Regression.\n",
        "\n",
        "1. Type of Classification\n",
        "Logistic Regression:\n",
        "\n",
        "Binary classification (two classes).\n",
        "It is used when the target variable has two possible outcomes, typically coded as 0 or 1 (e.g., spam or not spam).\n",
        "Logistic Regression outputs a probability for class 1 (positive class), and class 0 is simply the complement (i.e.,\n",
        "𝑃\n",
        "(\n",
        "𝑦\n",
        "=\n",
        "0\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "𝑃\n",
        "(\n",
        "𝑦\n",
        "=\n",
        "1\n",
        ")\n",
        "P(y=0)=1−P(y=1)).\n",
        "Softmax Regression:\n",
        "\n",
        "Multiclass classification (more than two classes).\n",
        "It is an extension of Logistic Regression used for multi-class problems where the target variable can take more than two distinct values (e.g., classifying images into one of several categories, such as dog, cat, and horse).\n",
        "Softmax Regression provides a probability distribution across all classes, summing to 1.\n",
        "2. Output\n",
        "Logistic Regression:\n",
        "\n",
        "The output is a single probability indicating the likelihood of an instance belonging to the positive class (class 1).\n",
        "The prediction is made by applying a threshold (usually 0.5) to this probability. If the probability is greater than 0.5, the model predicts class 1; otherwise, it predicts class 0.\n",
        "Softmax Regression:\n",
        "\n",
        "The output is a vector of probabilities corresponding to each class in the multiclass problem. The sum of all probabilities equals 1, and each class has a probability value between 0 and 1.\n",
        "Softmax Regression calculates a separate probability for each class, and the class with the highest probability is chosen as the predicted class.\n",
        "3. Function Used for Prediction\n",
        "Logistic Regression:\n",
        "\n",
        "Logistic Regression uses the sigmoid function (also called the logistic function) to map the linear combination of input features to a probability:\n",
        "𝑃\n",
        "(\n",
        "𝑦\n",
        "=\n",
        "1\n",
        "∣\n",
        "𝑋\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "𝑒\n",
        "−\n",
        "(\n",
        "𝛽\n",
        "0\n",
        "+\n",
        "𝛽\n",
        "1\n",
        "𝑋\n",
        "1\n",
        "+\n",
        "⋯\n",
        "+\n",
        "𝛽\n",
        "𝑛\n",
        "𝑋\n",
        "𝑛\n",
        ")\n",
        "P(y=1∣X)=\n",
        "1+e\n",
        "−(β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " X\n",
        "1\n",
        "​\n",
        " +⋯+β\n",
        "n\n",
        "​\n",
        " X\n",
        "n\n",
        "​\n",
        " )\n",
        "\n",
        "1\n",
        "​\n",
        "\n",
        "It produces a single probability for the positive class.\n",
        "Softmax Regression:\n",
        "\n",
        "Softmax Regression uses the softmax function to compute the probabilities of each class for multiclass problems:\n",
        "𝑃\n",
        "(\n",
        "𝑦\n",
        "=\n",
        "𝑘\n",
        "∣\n",
        "𝑋\n",
        ")\n",
        "=\n",
        "𝑒\n",
        "𝛽\n",
        "𝑘\n",
        "𝑋\n",
        "∑\n",
        "𝑗\n",
        "=\n",
        "1\n",
        "𝐾\n",
        "𝑒\n",
        "𝛽\n",
        "𝑗\n",
        "𝑋\n",
        "P(y=k∣X)=\n",
        "∑\n",
        "j=1\n",
        "K\n",
        "​\n",
        " e\n",
        "β\n",
        "j\n",
        "​\n",
        " X\n",
        "\n",
        "e\n",
        "β\n",
        "k\n",
        "​\n",
        " X\n",
        "\n",
        "​\n",
        "\n",
        "Where\n",
        "𝐾\n",
        "K is the number of classes,\n",
        "𝛽\n",
        "𝑘\n",
        "β\n",
        "k\n",
        "​\n",
        "  is the weight for class\n",
        "𝑘\n",
        "k, and the denominator is the sum of the exponentiated weights for all classes, ensuring that the probabilities across all classes sum to 1.\n",
        "4. Model Complexity\n",
        "Logistic Regression:\n",
        "\n",
        "Simpler, as it only deals with two classes.\n",
        "A single set of coefficients is learned, one for the positive class, and the other class is treated implicitly as the complement.\n",
        "Softmax Regression:\n",
        "\n",
        "More complex, as it deals with multiple classes.\n",
        "It requires learning a separate set of coefficients for each class (one per class), and it calculates probabilities for all classes simultaneously.\n",
        "5. Number of Classes Handled\n",
        "Logistic Regression:\n",
        "Designed for binary classification problems, where there are only two possible outcomes.\n",
        "Softmax Regression:\n",
        "Handles multiclass classification problems, where there are more than two possible outcomes (e.g., predicting one of several categories).\n",
        "6. Decision Boundary\n",
        "Logistic Regression:\n",
        "\n",
        "Creates a single decision boundary between the two classes. It defines a threshold at a probability of 0.5, above which it predicts one class (positive class) and below which it predicts the other class (negative class).\n",
        "Softmax Regression:\n",
        "\n",
        "Creates multiple decision boundaries, one for each pair of classes, since it must compare the probabilities for each class to make a decision.\n",
        "It predicts the class with the highest probability.\n",
        "7. Loss Function\n",
        "Logistic Regression:\n",
        "\n",
        "Uses the Binary Cross-Entropy Loss (also known as log loss) for binary classification:\n",
        "𝐿\n",
        "=\n",
        "−\n",
        "(\n",
        "𝑦\n",
        "⋅\n",
        "log\n",
        "⁡\n",
        "(\n",
        "𝑝\n",
        ")\n",
        "+\n",
        "(\n",
        "1\n",
        "−\n",
        "𝑦\n",
        ")\n",
        "⋅\n",
        "log\n",
        "⁡\n",
        "(\n",
        "1\n",
        "−\n",
        "𝑝\n",
        ")\n",
        ")\n",
        "L=−(y⋅log(p)+(1−y)⋅log(1−p))\n",
        "Where\n",
        "𝑦\n",
        "y is the true label, and\n",
        "𝑝\n",
        "p is the predicted probability of the positive class.\n",
        "Softmax Regression:\n",
        "\n",
        "Uses the Categorical Cross-Entropy Loss (also known as multiclass log loss) for multiclass classification:\n",
        "𝐿\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑘\n",
        "=\n",
        "1\n",
        "𝐾\n",
        "𝑦\n",
        "𝑘\n",
        "⋅\n",
        "log\n",
        "⁡\n",
        "(\n",
        "𝑝\n",
        "𝑘\n",
        ")\n",
        "L=−\n",
        "k=1\n",
        "∑\n",
        "K\n",
        "​\n",
        " y\n",
        "k\n",
        "​\n",
        " ⋅log(p\n",
        "k\n",
        "​\n",
        " )\n",
        "Where\n",
        "𝑦\n",
        "𝑘\n",
        "y\n",
        "k\n",
        "​\n",
        "  is the one-hot encoded true class, and\n",
        "𝑝\n",
        "𝑘\n",
        "p\n",
        "k\n",
        "​\n",
        "  is the predicted probability for class\n",
        "𝑘\n",
        "k.\n",
        "8. Extension to Multiclass\n",
        "Logistic Regression:\n",
        "\n",
        "Logistic Regression is not naturally designed for multiclass classification, but it can be extended to multiclass problems using the One-vs-Rest (OvR) or One-vs-All (OvA) approach. In OvR, one classifier is trained for each class to distinguish it from the others.\n",
        "Softmax Regression:\n",
        "\n",
        "Softmax Regression is natively designed for multiclass classification. It directly computes a probability distribution across all possible classes in a single model."
      ],
      "metadata": {
        "id": "u-BbEeUbqbT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#19. How do we choose between One-vs-Rest (OVR) and Softmax for multiclass classification?\n",
        "Choosing Between One-vs-Rest (OvR) and Softmax for Multiclass Classification\n",
        "Both One-vs-Rest (OvR) and Softmax Regression are commonly used strategies for solving multiclass classification problems, but the choice between them depends on several factors such as the model complexity, performance requirements, and the nature of the dataset. Below is a detailed breakdown of each approach and factors to consider when choosing between them.\n",
        "\n",
        "1. One-vs-Rest (OvR) Approach\n",
        "Description:\n",
        "\n",
        "In the One-vs-Rest (OvR) strategy, a separate binary classifier is trained for each class. For a dataset with\n",
        "𝐾\n",
        "K classes, we train\n",
        "𝐾\n",
        "K classifiers, where each classifier learns to distinguish one class from the rest.\n",
        "Each classifier outputs a probability of whether an instance belongs to that specific class or not.\n",
        "For prediction, the class with the highest probability from all classifiers is chosen as the final predicted class.\n",
        "Characteristics:\n",
        "\n",
        "Binary Classification: Each classifier is a binary classifier, making the OvR approach more similar to training multiple logistic regression models.\n",
        "Multiple Binary Classifiers: Requires training multiple classifiers, one for each class.\n",
        "Prediction Process: After the model is trained, the prediction involves calculating probabilities from each of the\n",
        "𝐾\n",
        "K binary classifiers and selecting the class with the highest probability.\n",
        "2. Softmax Regression\n",
        "Description:\n",
        "\n",
        "Softmax Regression (also called multinomial logistic regression) is a direct extension of logistic regression to multiclass problems.\n",
        "Instead of training multiple binary classifiers, Softmax Regression models the entire multiclass problem by calculating a probability distribution over all\n",
        "𝐾\n",
        "K classes using a single classifier.\n",
        "The softmax function is used to convert the raw output (logits) into class probabilities, ensuring that the sum of probabilities across all classes is equal to 1.\n",
        "Characteristics:\n",
        "\n",
        "Single Model: Softmax regression directly learns a model that classifies data into one of\n",
        "𝐾\n",
        "K classes.\n",
        "Simultaneous Probabilities: It calculates probabilities for all classes in a single forward pass.\n",
        "Output: Provides a probability distribution across all classes, and the class with the highest probability is selected as the final prediction.\n",
        "Key Considerations for Choosing Between OvR and Softmax\n",
        "1. Number of Classes\n",
        "OvR: Works well when the number of classes is moderate (not too large), as it trains\n",
        "𝐾\n",
        "K binary classifiers. However, when the number of classes is very large, training a separate model for each class can become computationally expensive.\n",
        "Softmax: Softmax is ideal for multiclass problems with many classes because it trains a single model for all classes, making it more computationally efficient in such scenarios.\n",
        "2. Computational Efficiency\n",
        "OvR: Requires training multiple classifiers (one per class). This can be computationally expensive when there are many classes, as each classifier must be trained and evaluated separately. Also, inference involves calculating probabilities for each classifier.\n",
        "Softmax: Requires training a single model for all classes. After training, inference is more efficient, as only a single pass is needed to compute the class probabilities.\n",
        "3. Model Performance\n",
        "OvR: The performance of each individual classifier is independent, which may result in suboptimal performance when the classes are not equally distributed or when there is high correlation between classes. Additionally, class imbalance could affect OvR models, as the classifiers might be biased toward the dominant class.\n",
        "Softmax: Since Softmax handles all classes simultaneously, it may perform better in cases where class correlation is high or when the class distribution is more balanced. Softmax accounts for all classes together during training, which can improve overall performance.\n",
        "4. Training and Complexity\n",
        "OvR: Training\n",
        "𝐾\n",
        "K binary classifiers separately makes the training process more straightforward and modular. However, each individual classifier may overfit on its own, leading to inconsistencies when combined.\n",
        "Softmax: In contrast, Softmax requires training a single model on all classes at once. This can be more challenging as it requires balancing the learning process across all classes. However, it can be more stable, as it optimizes for all classes simultaneously.\n",
        "5. Multi-label vs. Multiclass\n",
        "OvR: OvR can be extended to multi-label classification (where multiple labels can be assigned to a single sample), because each classifier only cares about one class at a time. Each classifier can output a \"yes\" or \"no\" decision, allowing you to treat each class independently.\n",
        "Softmax: Softmax is strictly for multiclass classification, where each sample is assigned to exactly one class. It cannot handle multi-label problems directly.\n",
        "6. Calibration of Probabilities\n",
        "OvR: Each individual binary classifier trained in OvR may not be well-calibrated, meaning the probabilities outputted by each classifier may not reflect the true likelihood of the class. Combining the results from several classifiers may lead to less reliable probability estimates.\n",
        "Softmax: Since Softmax is designed to output a probability distribution over all classes, the probabilities it provides are generally better calibrated. This makes Softmax a better option if the goal is to interpret the confidence of class predictions.\n",
        "When to Choose One-vs-Rest (OvR) Over Softmax?\n",
        "Smaller Number of Classes: If you have a problem with a small or moderate number of classes (say 2-10), OvR might be simpler to implement and computationally feasible.\n",
        "Class Imbalance: If you have highly imbalanced classes (e.g., one class is much more frequent than others), OvR might perform better since you can focus on handling each class individually with custom methods like class weighting.\n",
        "Computational Simplicity: OvR may be preferred when you want to experiment with different classifiers for each class or if you're using models like SVMs (Support Vector Machines), which naturally lend themselves to binary classification tasks.\n",
        "When to Choose Softmax Regression Over OvR?\n",
        "Larger Number of Classes: If the number of classes is large, Softmax is generally more efficient, as it avoids training multiple models.\n",
        "Better Model Performance: If your classes are correlated or there is no clear boundary between them, Softmax will likely produce more accurate predictions because it considers all classes together.\n",
        "Probability Calibration: If you need well-calibrated class probabilities (e.g., for probabilistic interpretation or decision-making), Softmax provides a better probability distribution over all classes.\n",
        "Multiclass Tasks: If the problem is strictly multiclass (not multi-label), Softmax is a more natural choice, as it is designed specifically for multiclass classification.\n"
      ],
      "metadata": {
        "id": "LVc8CuoUrDqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20. How do we interpret coefficients in Logistic Regression?\n",
        "Interpreting Coefficients in Logistic Regression\n",
        "In Logistic Regression, the coefficients (also called weights) provide insight into the relationship between the predictor variables (features) and the probability of the target event occurring. Unlike linear regression, which predicts a continuous outcome, logistic regression predicts the probability that a given observation belongs to a particular class.\n",
        "\n",
        "Logistic regression uses the logistic function (sigmoid function) to model the relationship between the predictors and the probability of the outcome. The logistic regression model is typically represented as:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝑦\n",
        "=\n",
        "1\n",
        "∣\n",
        "𝑋\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "𝑒\n",
        "−\n",
        "(\n",
        "𝛽\n",
        "0\n",
        "+\n",
        "𝛽\n",
        "1\n",
        "𝑋\n",
        "1\n",
        "+\n",
        "⋯\n",
        "+\n",
        "𝛽\n",
        "𝑛\n",
        "𝑋\n",
        "𝑛\n",
        ")\n",
        "P(y=1∣X)=\n",
        "1+e\n",
        "−(β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " X\n",
        "1\n",
        "​\n",
        " +⋯+β\n",
        "n\n",
        "​\n",
        " X\n",
        "n\n",
        "​\n",
        " )\n",
        "\n",
        "1\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝑦\n",
        "=\n",
        "1\n",
        "∣\n",
        "𝑋\n",
        ")\n",
        "P(y=1∣X) is the probability that the outcome\n",
        "𝑦\n",
        "y is 1 (e.g., \"success\" or \"positive class\").\n",
        "𝛽\n",
        "0\n",
        "β\n",
        "0\n",
        "​\n",
        "  is the intercept.\n",
        "𝛽\n",
        "1\n",
        ",\n",
        "𝛽\n",
        "2\n",
        ",\n",
        "…\n",
        ",\n",
        "𝛽\n",
        "𝑛\n",
        "β\n",
        "1\n",
        "​\n",
        " ,β\n",
        "2\n",
        "​\n",
        " ,…,β\n",
        "n\n",
        "​\n",
        "  are the coefficients for the features\n",
        "𝑋\n",
        "1\n",
        ",\n",
        "𝑋\n",
        "2\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑋\n",
        "𝑛\n",
        "X\n",
        "1\n",
        "​\n",
        " ,X\n",
        "2\n",
        "​\n",
        " ,…,X\n",
        "n\n",
        "​\n",
        " .\n",
        "𝑒\n",
        "e is the base of the natural logarithm.\n",
        "Interpretation of Coefficients\n",
        "The coefficients in logistic regression are estimated in such a way that they describe the log-odds of the outcome being 1. The log-odds are the natural log of the odds, where the odds are the ratio of the probability of the event happening to the probability of the event not happening.\n",
        "\n",
        "1. The Log-Odds Interpretation\n",
        "Each coefficient\n",
        "𝛽\n",
        "𝑖\n",
        "β\n",
        "i\n",
        "​\n",
        "  represents the change in the log-odds of the outcome being 1 for a one-unit increase in the corresponding feature\n",
        "𝑋\n",
        "𝑖\n",
        "X\n",
        "i\n",
        "​\n",
        " , holding all other features constant.\n",
        "\n",
        "Log-Odds: The log-odds of the event (the target variable being 1) is defined as:\n",
        "Log-Odds\n",
        "=\n",
        "ln\n",
        "⁡\n",
        "(\n",
        "𝑃\n",
        "(\n",
        "𝑦\n",
        "=\n",
        "1\n",
        "∣\n",
        "𝑋\n",
        ")\n",
        "1\n",
        "−\n",
        "𝑃\n",
        "(\n",
        "𝑦\n",
        "=\n",
        "1\n",
        "∣\n",
        "𝑋\n",
        ")\n",
        ")\n",
        "Log-Odds=ln(\n",
        "1−P(y=1∣X)\n",
        "P(y=1∣X)\n",
        "​\n",
        " )\n",
        "So, for each feature:\n",
        "\n",
        "A positive coefficient\n",
        "𝛽\n",
        "𝑖\n",
        ">\n",
        "0\n",
        "β\n",
        "i\n",
        "​\n",
        " >0 increases the log-odds, meaning that as the value of\n",
        "𝑋\n",
        "𝑖\n",
        "X\n",
        "i\n",
        "​\n",
        "  increases, the probability of the event occurring (i.e.,\n",
        "𝑦\n",
        "=\n",
        "1\n",
        "y=1) increases.\n",
        "A negative coefficient\n",
        "𝛽\n",
        "𝑖\n",
        "<\n",
        "0\n",
        "β\n",
        "i\n",
        "​\n",
        " <0 decreases the log-odds, meaning that as the value of\n",
        "𝑋\n",
        "𝑖\n",
        "X\n",
        "i\n",
        "​\n",
        "  increases, the probability of the event occurring decreases.\n",
        "2. Odds Ratio Interpretation\n",
        "To make the interpretation easier, we often exponentiate the coefficients to get the odds ratio (OR), which is easier to interpret directly. The odds ratio tells us how much the odds of the event change with a one-unit increase in the predictor variable.\n",
        "\n",
        "Odds Ratio\n",
        "=\n",
        "𝑒\n",
        "𝛽\n",
        "𝑖\n",
        "Odds Ratio=e\n",
        "β\n",
        "i\n",
        "​\n",
        "\n",
        "\n",
        "If\n",
        "𝑒\n",
        "𝛽\n",
        "𝑖\n",
        ">\n",
        "1\n",
        "e\n",
        "β\n",
        "i\n",
        "​\n",
        "\n",
        " >1, the feature\n",
        "𝑋\n",
        "𝑖\n",
        "X\n",
        "i\n",
        "​\n",
        "  increases the odds of the event occurring.\n",
        "If\n",
        "𝑒\n",
        "𝛽\n",
        "𝑖\n",
        "<\n",
        "1\n",
        "e\n",
        "β\n",
        "i\n",
        "​\n",
        "\n",
        " <1, the feature\n",
        "𝑋\n",
        "𝑖\n",
        "X\n",
        "i\n",
        "​\n",
        "  decreases the odds of the event occurring.\n",
        "If\n",
        "𝑒\n",
        "𝛽\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "e\n",
        "β\n",
        "i\n",
        "​\n",
        "\n",
        " =1, the feature\n",
        "𝑋\n",
        "𝑖\n",
        "X\n",
        "i\n",
        "​\n",
        "  has no effect on the odds.\n",
        "3. Example Interpretation\n",
        "Let's say you have a logistic regression model predicting whether a customer will buy a product (1 = buy, 0 = no buy), and you have two features: income and age.\n",
        "\n",
        "The coefficients of the model might look like this:\n",
        "\n",
        "logit\n",
        "(\n",
        "𝑃\n",
        "(\n",
        "buy\n",
        "=\n",
        "1\n",
        "∣\n",
        "income\n",
        ",\n",
        "age\n",
        ")\n",
        ")\n",
        "=\n",
        "−\n",
        "3\n",
        "+\n",
        "0.02\n",
        "×\n",
        "income\n",
        "+\n",
        "0.05\n",
        "×\n",
        "age\n",
        "logit(P(buy=1∣income,age))=−3+0.02×income+0.05×age\n",
        "Now, let's interpret the coefficients:\n",
        "\n",
        "Intercept (\n",
        "𝛽\n",
        "0\n",
        "=\n",
        "−\n",
        "3\n",
        "β\n",
        "0\n",
        "​\n",
        " =−3): When both income and age are zero (which is unrealistic in this context), the log-odds of buying are -3. This is the baseline log-odds for the model when no features are present.\n",
        "\n",
        "Coefficient for income (\n",
        "𝛽\n",
        "1\n",
        "=\n",
        "0.02\n",
        "β\n",
        "1\n",
        "​\n",
        " =0.02): For each additional unit increase in income, the log-odds of buying increase by 0.02, holding age constant.\n",
        "\n",
        "Exponentiating this coefficient,\n",
        "𝑒\n",
        "0.02\n",
        "≈\n",
        "1.02\n",
        "e\n",
        "0.02\n",
        " ≈1.02, which means that for each additional unit increase in income, the odds of buying increase by 2%.\n",
        "Coefficient for age (\n",
        "𝛽\n",
        "2\n",
        "=\n",
        "0.05\n",
        "β\n",
        "2\n",
        "​\n",
        " =0.05): For each additional year of age, the log-odds of buying increase by 0.05, holding income constant.\n",
        "\n",
        "Exponentiating this coefficient,\n",
        "𝑒\n",
        "0.05\n",
        "≈\n",
        "1.05\n",
        "e\n",
        "0.05\n",
        " ≈1.05, which means that for each additional year of age, the odds of buying increase by 5%.\n",
        "4. Important Points to Remember\n",
        "Scaling of Features: Logistic regression coefficients are sensitive to the scaling of features. For example, if one feature is measured in thousands (e.g., income in dollars) and another in single units (e.g., age in years), the coefficients might be hard to interpret directly. It’s often a good practice to standardize or normalize features before interpreting the coefficients.\n",
        "\n",
        "Non-linear Relationships: Logistic regression assumes a linear relationship between the predictor variables and the log-odds of the outcome. If the relationship is non-linear, the model may not perform well, and the coefficients' interpretation may become less meaningful.\n",
        "\n",
        "Multicollinearity: If there is high correlation between the predictor variables (multicollinearity), the coefficients may become unstable, making interpretation difficult. Regularization techniques like Ridge or Lasso can help mitigate multicollinearity.\n",
        "\n",
        "Conclusion\n",
        "The coefficients in Logistic Regression represent the change in the log-odds of the outcome being 1 for a one-unit change in the corresponding predictor variable. By exponentiating these coefficients, you can obtain the odds ratio, which is easier to interpret in practical terms. The key to interpreting coefficients is understanding that:\n",
        "\n",
        "A positive coefficient increases the odds of the outcome.\n",
        "A negative coefficient decreases the odds of the outcome.\n",
        "A coefficient of zero means no effect on the odds.\n",
        "When interpreting coefficients, it’s important to consider feature scaling, the presence of multicollinearity, and the linearity assumption of the model.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yVXfvMd7rbSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PRACTICAL"
      ],
      "metadata": {
        "id": "evzgOsrgtflh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.\n",
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (Iris dataset in this case)\n",
        "data = load_iris()\n",
        "X = data.data  # Feature matrix\n",
        "y = data.target  # Target vector\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the model accuracy\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0BdQbocthoB",
        "outputId": "9c660059-40d4-4c3b-991a-8f0544f0b8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Write a Python program to apply LI regularization (Lasso) on a dataset using LogisticRegression(penalty) and print the model accuracy.\n",
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (Iris dataset in this case)\n",
        "data = load_iris()\n",
        "X = data.data  # Feature matrix\n",
        "y = data.target  # Target vector\n",
        "\n",
        "# Convert target to binary classification for simplicity (class 0 vs. class 1)\n",
        "y_binary = (y == 0).astype(int)  # Create a binary target: 1 if class is 0, else 0\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression model with L1 regularization (Lasso)\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=200)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the model accuracy\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PqEjT9Ttsf3",
        "outputId": "8a50a7b2-54cb-4822-941b-92f186d1d412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Write a Python program to train Logistic Regression with 12 regularization (Ridge) using LogisticRegression(penalty='12'). Print model accuracy and coefficients.\n",
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (Iris dataset in this case)\n",
        "data = load_iris()\n",
        "X = data.data  # Feature matrix\n",
        "y = data.target  # Target vector\n",
        "\n",
        "# Convert target to binary classification for simplicity (class 0 vs. class 1)\n",
        "y_binary = (y == 0).astype(int)  # Create a binary target: 1 if class is 0, else 0\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression model with L2 regularization (Ridge)\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear', max_iter=200)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the model accuracy\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print the coefficients (weights) of the model\n",
        "print(f\"Model Coefficients: {model.coef_}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNncGgIKt6oI",
        "outputId": "6b1ef956-3b15-41e3-9aa0-cf824219d870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 100.00%\n",
            "Model Coefficients: [[ 0.3711229   1.409712   -2.15210117 -0.95474179]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty elasticnet).\n",
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (Iris dataset in this case)\n",
        "data = load_iris()\n",
        "X = data.data  # Feature matrix\n",
        "y = data.target  # Target vector\n",
        "\n",
        "# Convert target to binary classification for simplicity (class 0 vs. class 1)\n",
        "y_binary = (y == 0).astype(int)  # Create a binary target: 1 if class is 0, else 0\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression model with Elastic Net regularization\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=200)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the model accuracy\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print the coefficients (weights) of the model\n",
        "print(f\"Model Coefficients: {model.coef_}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrGRP6Ehvc5k",
        "outputId": "43520658-ff65-450e-8427-566a70d1b73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 100.00%\n",
            "Model Coefficients: [[ 0.17096131  1.57233102 -2.32688821 -0.63881133]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Write a Python program to train a Logistic Regression model for multiclass classification using multi class='ovr\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (Iris dataset in this case)\n",
        "data = load_iris()\n",
        "X = data.data  # Feature matrix\n",
        "y = data.target  # Target vector (multiclass)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression model with One-vs-Rest (OvR) for multiclass classification\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=200)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the model accuracy\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print the coefficients (weights) of the model for each class\n",
        "print(f\"Model Coefficients: {model.coef_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaIWOkTVvo-z",
        "outputId": "a53f91a5-fb83-49a0-c138-fd1667ec4236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 100.00%\n",
            "Model Coefficients: [[ 0.3711229   1.409712   -2.15210117 -0.95474179]\n",
            " [ 0.49400451 -1.58897112  0.43717015 -1.11187838]\n",
            " [-1.55895271 -1.58893375  2.39874554  2.15556209]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy\n",
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (Iris dataset in this case)\n",
        "data = load_iris()\n",
        "X = data.data  # Feature matrix\n",
        "y = data.target  # Target vector\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l2', 'l1']  # Regularization type (L2 and L1)\n",
        "}\n",
        "\n",
        "# Apply GridSearchCV to find the best parameters\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters from the grid search\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Print the best parameters\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "# Get the best model from the grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy of the best model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the model accuracy\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVd5AcZdv2kn",
        "outputId": "9d25e909-5970-4c19-9a7e-f01f29d2bbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 1, 'penalty': 'l2'}\n",
            "Model Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.85833333        nan 0.93333333        nan 0.96666667        nan\n",
            " 0.94166667        nan 0.95              nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy,\n",
        "# Import necessary libraries\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "# Load a sample dataset (Iris dataset in this case)\n",
        "data = load_iris()\n",
        "X = data.data  # Feature matrix\n",
        "y = data.target  # Target vector\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Define Stratified K-Fold Cross-Validation with 5 splits\n",
        "stratified_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate the model using Stratified K-Fold Cross-Validation\n",
        "scores = cross_val_score(model, X, y, cv=stratified_k_fold, scoring='accuracy')\n",
        "\n",
        "# Calculate the average accuracy\n",
        "average_accuracy = np.mean(scores)\n",
        "\n",
        "# Print the accuracy for each fold and the average accuracy\n",
        "print(f\"Accuracy for each fold: {scores}\")\n",
        "print(f\"Average Accuracy: {average_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7Zvoq-uwGTH",
        "outputId": "17a52fd7-659f-4d2f-9cfa-ff3089db3ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for each fold: [1.         0.96666667 0.93333333 1.         0.93333333]\n",
            "Average Accuracy: 96.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy,\n",
        "# Import necessary libraries\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load dataset from a CSV file\n",
        "# Replace 'your_dataset.csv' with the actual path of your CSV file\n",
        "# I will create sample_data.csv here to test this code\n",
        "data = pd.DataFrame({'Name': ['vidhu', 'puneet', 'soniya', 'sandeep'], 'Age': [23, 32, 21, 33], 'Salary': ['low','medium','high','medium']})\n",
        "data.to_csv('sample_data.csv', index=False)\n",
        "data = pd.read_csv('sample_data.csv')\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "print(data.head())\n",
        "\n",
        "# Assuming the target variable is the last column and the rest are features\n",
        "X = data.iloc[:, :-1]  # All columns except the last one are features\n",
        "y = data.iloc[:, -1]   # The last column is the target variable\n",
        "\n",
        "# Convert categorical columns in X to numeric using LabelEncoder\n",
        "label_encoder_X = LabelEncoder()\n",
        "#We will need to create an encoder for each categorical feature we want to convert\n",
        "X['Name'] = label_encoder_X.fit_transform(X['Name'])\n",
        "\n",
        "# If the target variable is categorical, convert it to numeric using LabelEncoder\n",
        "label_encoder_y = LabelEncoder()\n",
        "y = label_encoder_y.fit_transform(y)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGxugCbjwQu2",
        "outputId": "e5b1cdd7-5249-4d8a-93e1-c2d183078269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Name  Age  Salary\n",
            "0    vidhu   23     low\n",
            "1   puneet   32  medium\n",
            "2   soniya   21    high\n",
            "3  sandeep   33  medium\n",
            "Model Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Wite a Python program to apply Randomized SearchCV for tuning hyperparameters (C. penalty, solver) in Logistic Regression. Print the best parameters and accuracy.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Define the parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'C': uniform(loc=0.1, scale=10),  # Random values for the penalty strength\n",
        "    'solver': ['liblinear', 'saga', 'lbfgs']  # Different solvers to test\n",
        "}\n",
        "\n",
        "# Set up the RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=logreg, param_distributions=param_dist, n_iter=100, cv=5, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit the RandomizedSearchCV on the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and model\n",
        "best_params = random_search.best_params_\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Test Set Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "OasGjQ8uwa9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10. Write a Python program to implement One-vs-One (OVO) Multiclass Logistic Regression and print accuracy\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset (Iris dataset for classification)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Initialize the OneVsOneClassifier with Logistic Regression\n",
        "ovo_classifier = OneVsOneClassifier(logreg)\n",
        "\n",
        "# Fit the model on the training data\n",
        "ovo_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = ovo_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Accuracy of One-vs-One Multiclass Logistic Regression: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFd1yavUAbGE",
        "outputId": "c373b567-9eae-4965-bad2-e8b6da3ada51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of One-vs-One Multiclass Logistic Regression: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#11. Write a Python program to train a Logistic Regression model and visualize the contusion matrix for binary classification.\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Load the breast cancer dataset (binary classification)\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Train the model on the training set\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Calculate accuracy (optional)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Predicted: 0\", \"Predicted: 1\"], yticklabels=[\"Actual: 0\", \"Actual: 1\"])\n",
        "plt.title(\"Confusion Matrix for Logistic Regression\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"Actual Labels\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "VqH-gxWpAnxW",
        "outputId": "8dd62baf-09b7-4403-ea8a-bb0c758a44e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9766\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision Recall, and FI-Score\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Load the breast cancer dataset (binary classification)\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Train the model on the training set\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Evaluate the model using Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOlFdBbEA5_S",
        "outputId": "6d092cb7-b0cd-4190-d23a-4960df89eeb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9766\n",
            "Precision: 0.9815\n",
            "Recall: 0.9815\n",
            "F1-Score: 0.9815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Generate an imbalanced dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2,\n",
        "                           n_clusters_per_class=1, weights=[0.9, 0.1],\n",
        "                           flip_y=0, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression with class weights balanced\n",
        "logreg = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
        "\n",
        "# Train the model on the training set\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Print classification report (precision, recall, f1-score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Visualize the distribution of the classes\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.hist(y_train, bins=2, edgecolor='black', alpha=0.7)\n",
        "plt.title(\"Distribution of Classes (Imbalanced Dataset)\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.xticks([0, 1], ['Class 0', 'Class 1'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "Uwf2A06CBVH-",
        "outputId": "a3a32b15-8092-410c-da02-052473b55ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9433\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.94      0.97       270\n",
            "           1       0.65      0.93      0.77        30\n",
            "\n",
            "    accuracy                           0.94       300\n",
            "   macro avg       0.82      0.94      0.87       300\n",
            "weighted avg       0.96      0.94      0.95       300\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load Titanic dataset from seaborn or a CSV file\n",
        "# Example: If the dataset is a CSV file, load it using pd.read_csv() like so:\n",
        "# df = pd.read_csv(\"titanic.csv\")\n",
        "import seaborn as sns\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Handle missing values:\n",
        "# 1. For numerical columns (e.g., Age, Fare), we'll fill missing values with the median.\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['fare'].fillna(df['fare'].median(), inplace=True)\n",
        "\n",
        "# 2. For categorical columns (e.g., Embarked), we'll fill missing values with the mode.\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns that aren't useful for prediction (e.g., Name, Ticket, Cabin)\n",
        "df.drop(columns=['name', 'ticket', 'cabin'], inplace=True)\n",
        "\n",
        "# Convert categorical variables into numeric (e.g., Sex, Embarked):\n",
        "# Use LabelEncoder for binary categorical variables like 'sex'\n",
        "label_encoder = LabelEncoder()\n",
        "df['sex'] = label_encoder.fit_transform(df['sex'])\n",
        "\n",
        "# Use one-hot encoding for 'embarked' since it has more than two categories\n",
        "df = pd.get_dummies(df, columns=['embarked'], drop_first=True)\n",
        "\n",
        "# Drop the 'survived' column and separate it as the target variable\n",
        "X = df.drop(columns='survived')\n",
        "y = df['survived']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Train the model\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Print classification report for precision, recall, and F1-score\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "laqr3x_uBnqY",
        "outputId": "3f4035b5-a140-4295-ede7-5fff54ce40a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-51c012e4016f>:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['age'].fillna(df['age'].median(), inplace=True)\n",
            "<ipython-input-19-51c012e4016f>:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['fare'].fillna(df['fare'].median(), inplace=True)\n",
            "<ipython-input-19-51c012e4016f>:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['name', 'ticket', 'cabin'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-51c012e4016f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Drop columns that aren't useful for prediction (e.g., Name, Ticket, Cabin)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ticket'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cabin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Convert categorical variables into numeric (e.g., Sex, Embarked):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['name', 'ticket', 'cabin'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset (You can replace it with another dataset like Titanic)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 1. Without Scaling:\n",
        "# Initialize Logistic Regression model\n",
        "logreg_no_scaling = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Train the model without scaling\n",
        "logreg_no_scaling.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_no_scaling = logreg_no_scaling.predict(X_test)\n",
        "\n",
        "# Calculate accuracy without scaling\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling:.4f}\")\n",
        "\n",
        "# 2. With Scaling (Standardization):\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the training data, then transform the test data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize Logistic Regression model again\n",
        "logreg_with_scaling = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Train the model with scaled data\n",
        "logreg_with_scaling.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_with_scaling = logreg_with_scaling.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy with scaling\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
        "print(f\"Accuracy with scaling: {accuracy_with_scaling:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQjLsWSXByRn",
        "outputId": "0869de2d-78e5-4bf7-d602-23eb415c0a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.0000\n",
            "Accuracy with scaling: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Generate synthetic dataset (or load your dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "data, labels = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features (optional but recommended for logistic regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model with custom regularization strength (C=0.5)\n",
        "model = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and evaluate ROC-AUC score\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DErcjfCDCgC",
        "outputId": "670e5881-141d-45e6-a769-c6ce01cfaade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#17. Write a Python program to train Logistic Regression Using a custom learning rate (C=0.5) and evaluate accuracy.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic dataset (or load your dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "data, labels = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features (optional but recommended for logistic regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model with custom regularization strength (C=0.5)\n",
        "model = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycKavPx-DRsY",
        "outputId": "75a84bad-e0dc-4c0a-d628-db88ffbaed00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#18. Write a Python program to train Logistic Regression and identify important features based on model coefficients\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Generate synthetic dataset (or load your dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "data, labels = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features (optional but recommended for logistic regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model with custom regularization strength (C=0.5)\n",
        "model = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and evaluate ROC-AUC score\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Identify important features based on model coefficients\n",
        "feature_importance = pd.Series(model.coef_[0], index=[f'Feature {i}' for i in range(X_train.shape[1])])\n",
        "feature_importance = feature_importance.abs().sort_values(ascending=False)\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q163-quyHtlM",
        "outputId": "877f96b1-f060-4962-c262-301697335995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9125\n",
            "Feature Importance:\n",
            "Feature 6    1.607884\n",
            "Feature 2    1.154319\n",
            "Feature 8    1.027209\n",
            "Feature 0    0.507441\n",
            "Feature 5    0.214090\n",
            "Feature 1    0.156444\n",
            "Feature 9    0.092771\n",
            "Feature 3    0.053456\n",
            "Feature 4    0.041973\n",
            "Feature 7    0.004837\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen's Kappa Score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, cohen_kappa_score\n",
        "\n",
        "# Generate synthetic dataset (or load your dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "data, labels = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features (optional but recommended for logistic regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model with custom regularization strength (C=0.5)\n",
        "model = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and evaluate ROC-AUC score\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Predict classes and evaluate Cohen's Kappa Score\n",
        "y_pred = model.predict(X_test)\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Identify important features based on model coefficients\n",
        "feature_importance = pd.Series(model.coef_[0], index=[f'Feature {i}' for i in range(X_train.shape[1])])\n",
        "feature_importance = feature_importance.abs().sort_values(ascending=False)\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1i-HKvBIp5r",
        "outputId": "7f0adb89-6a73-458a-bed0-b34035b45d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9125\n",
            "Cohen's Kappa Score: 0.6581\n",
            "Feature Importance:\n",
            "Feature 6    1.607884\n",
            "Feature 2    1.154319\n",
            "Feature 8    1.027209\n",
            "Feature 0    0.507441\n",
            "Feature 5    0.214090\n",
            "Feature 1    0.156444\n",
            "Feature 9    0.092771\n",
            "Feature 3    0.053456\n",
            "Feature 4    0.041973\n",
            "Feature 7    0.004837\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, cohen_kappa_score, precision_recall_curve, auc\n",
        "\n",
        "# Generate synthetic dataset (or load your dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "data, labels = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features (optional but recommended for logistic regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model with custom regularization strength (C=0.5)\n",
        "model = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and evaluate ROC-AUC score\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Predict classes and evaluate Cohen's Kappa Score\n",
        "y_pred = model.predict(X_test)\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Identify important features based on model coefficients\n",
        "feature_importance = pd.Series(model.coef_[0], index=[f'Feature {i}' for i in range(X_train.shape[1])])\n",
        "feature_importance = feature_importance.abs().sort_values(ascending=False)\n",
        "\n",
        "# Compute Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label=f'PR AUC = {pr_auc:.4f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "mkrLcxhWI5jk",
        "outputId": "5ec5497b-0e4b-4512-9f5f-4203bbe03416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9125\n",
            "Cohen's Kappa Score: 0.6581\n",
            "Feature Importance:\n",
            "Feature 6    1.607884\n",
            "Feature 2    1.154319\n",
            "Feature 8    1.027209\n",
            "Feature 0    0.507441\n",
            "Feature 5    0.214090\n",
            "Feature 1    0.156444\n",
            "Feature 9    0.092771\n",
            "Feature 3    0.053456\n",
            "Feature 4    0.041973\n",
            "Feature 7    0.004837\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, Ibigs) and compare their accuracy.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, cohen_kappa_score, precision_recall_curve, auc, accuracy_score\n",
        "\n",
        "# Generate synthetic dataset (or load your dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "data, labels = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features (optional but recommended for logistic regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression models with different solvers and compare accuracy\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "accuracy_scores = {}\n",
        "\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(C=0.5, solver=solver, max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores[solver] = accuracy\n",
        "    print(f\"Solver: {solver}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Predict probabilities and evaluate ROC-AUC score\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Predict classes and evaluate Cohen's Kappa Score\n",
        "y_pred = model.predict(X_test)\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Identify important features based on model coefficients\n",
        "feature_importance = pd.Series(model.coef_[0], index=[f'Feature {i}' for i in range(X_train.shape[1])])\n",
        "feature_importance = feature_importance.abs().sort_values(ascending=False)\n",
        "\n",
        "# Compute Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label=f'PR AUC = {pr_auc:.4f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_importance)\n",
        "print(\"Accuracy Comparison:\")\n",
        "print(pd.Series(accuracy_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "UR2HVjAzP2Hs",
        "outputId": "dfcb26c9-0e65-4d54-f0d1-4ee812bab522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solver: liblinear, Accuracy: 0.8300\n",
            "Solver: saga, Accuracy: 0.8300\n",
            "Solver: lbfgs, Accuracy: 0.8300\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9125\n",
            "Cohen's Kappa Score: 0.6581\n",
            "Feature Importance:\n",
            "Feature 6    1.607884\n",
            "Feature 2    1.154319\n",
            "Feature 8    1.027209\n",
            "Feature 0    0.507441\n",
            "Feature 5    0.214090\n",
            "Feature 1    0.156444\n",
            "Feature 9    0.092771\n",
            "Feature 3    0.053456\n",
            "Feature 4    0.041973\n",
            "Feature 7    0.004837\n",
            "dtype: float64\n",
            "Accuracy Comparison:\n",
            "liblinear    0.83\n",
            "saga         0.83\n",
            "lbfgs        0.83\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC),\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, cohen_kappa_score, precision_recall_curve, auc, accuracy_score, matthews_corrcoef\n",
        "\n",
        "# Generate synthetic dataset (or load your dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "data, labels = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features (optional but recommended for logistic regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression models with different solvers and compare accuracy\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "accuracy_scores = {}\n",
        "\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(C=0.5, solver=solver, max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores[solver] = accuracy\n",
        "    print(f\"Solver: {solver}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Predict probabilities and evaluate ROC-AUC score\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Predict classes and evaluate Cohen's Kappa Score\n",
        "y_pred = model.predict(X_test)\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Compute Matthews Correlation Coefficient (MCC)\n",
        "mcc_score = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "# Identify important features based on model coefficients\n",
        "feature_importance = pd.Series(model.coef_[0], index=[f'Feature {i}' for i in range(X_train.shape[1])])\n",
        "feature_importance = feature_importance.abs().sort_values(ascending=False)\n",
        "\n",
        "# Compute Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label=f'PR AUC = {pr_auc:.4f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc_score:.4f}\")\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_importance)\n",
        "print(\"Accuracy Comparison:\")\n",
        "print(pd.Series(accuracy_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "R0CCUZHhWECE",
        "outputId": "fd2dc223-a5c6-48e4-a396-329feb5deeb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solver: liblinear, Accuracy: 0.8300\n",
            "Solver: saga, Accuracy: 0.8300\n",
            "Solver: lbfgs, Accuracy: 0.8300\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9125\n",
            "Cohen's Kappa Score: 0.6581\n",
            "Matthews Correlation Coefficient (MCC): 0.6593\n",
            "Feature Importance:\n",
            "Feature 6    1.607884\n",
            "Feature 2    1.154319\n",
            "Feature 8    1.027209\n",
            "Feature 0    0.507441\n",
            "Feature 5    0.214090\n",
            "Feature 1    0.156444\n",
            "Feature 9    0.092771\n",
            "Feature 3    0.053456\n",
            "Feature 4    0.041973\n",
            "Feature 7    0.004837\n",
            "dtype: float64\n",
            "Accuracy Comparison:\n",
            "liblinear    0.83\n",
            "saga         0.83\n",
            "lbfgs        0.83\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scalina\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, cohen_kappa_score, precision_recall_curve, auc, accuracy_score, matthews_corrcoef\n",
        "\n",
        "# Generate synthetic dataset (or load your dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "data, labels = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression on raw data\n",
        "model_raw = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000, random_state=42)\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression on standardized data\n",
        "model_scaled = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000, random_state=42)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Compare accuracy\n",
        "print(f\"Accuracy on raw data: {accuracy_raw:.4f}\")\n",
        "print(f\"Accuracy on standardized data: {accuracy_scaled:.4f}\")\n",
        "\n",
        "# Predict probabilities and evaluate ROC-AUC score\n",
        "y_prob = model_scaled.predict_proba(X_test_scaled)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Predict classes and evaluate Cohen's Kappa Score\n",
        "y_pred = model_scaled.predict(X_test_scaled)\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Compute Matthews Correlation Coefficient (MCC)\n",
        "mcc_score = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "# Identify important features based on model coefficients\n",
        "feature_importance = pd.Series(model_scaled.coef_[0], index=[f'Feature {i}' for i in range(X_train.shape[1])])\n",
        "feature_importance = feature_importance.abs().sort_values(ascending=False)\n",
        "\n",
        "# Compute Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label=f'PR AUC = {pr_auc:.4f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc_score:.4f}\")\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "id": "ktUKvcg-WXLI",
        "outputId": "72dd41e4-961b-4c99-d8bb-bc176d91664c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on raw data: 0.8300\n",
            "Accuracy on standardized data: 0.8300\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9125\n",
            "Cohen's Kappa Score: 0.6581\n",
            "Matthews Correlation Coefficient (MCC): 0.6593\n",
            "Feature Importance:\n",
            "Feature 6    1.607884\n",
            "Feature 2    1.154319\n",
            "Feature 8    1.027209\n",
            "Feature 0    0.507441\n",
            "Feature 5    0.214090\n",
            "Feature 1    0.156444\n",
            "Feature 9    0.092771\n",
            "Feature 3    0.053456\n",
            "Feature 4    0.041973\n",
            "Feature 7    0.004837\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, cohen_kappa_score, precision_recall_curve, auc, accuracy_score, matthews_corrcoef\n",
        "\n",
        "# Generate synthetic dataset (or load your dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "data, labels = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Find the optimal C using cross-validation\n",
        "C_values = np.logspace(-3, 3, 10)\n",
        "cv_scores = []\n",
        "\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(C=C, solver='lbfgs', max_iter=1000, random_state=42)\n",
        "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "    cv_scores.append(scores.mean())\n",
        "\n",
        "optimal_C = C_values[np.argmax(cv_scores)]\n",
        "print(f\"Optimal C: {optimal_C}\")\n",
        "\n",
        "# Train Logistic Regression with optimal C\n",
        "model_optimal = LogisticRegression(C=optimal_C, solver='lbfgs', max_iter=1000, random_state=42)\n",
        "model_optimal.fit(X_train_scaled, y_train)\n",
        "y_pred = model_optimal.predict(X_test_scaled)\n",
        "accuracy_optimal = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with optimal C: {accuracy_optimal:.4f}\")\n",
        "\n",
        "# Predict probabilities and evaluate ROC-AUC score\n",
        "y_prob = model_optimal.predict_proba(X_test_scaled)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Predict classes and evaluate Cohen's Kappa Score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Compute Matthews Correlation Coefficient (MCC)\n",
        "mcc_score = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "# Identify important features based on model coefficients\n",
        "feature_importance = pd.Series(model_optimal.coef_[0], index=[f'Feature {i}' for i in range(X_train.shape[1])])\n",
        "feature_importance = feature_importance.abs().sort_values(ascending=False)\n",
        "\n",
        "# Compute Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label=f'PR AUC = {pr_auc:.4f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc_score:.4f}\")\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "id": "qHPSA6U1XhY8",
        "outputId": "95fb92c0-9deb-4b33-9cb4-ef1425e0e0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C: 0.021544346900318832\n",
            "Accuracy with optimal C: 0.8250\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9103\n",
            "Cohen's Kappa Score: 0.6508\n",
            "Matthews Correlation Coefficient (MCC): 0.6563\n",
            "Feature Importance:\n",
            "Feature 6    0.961881\n",
            "Feature 2    0.732438\n",
            "Feature 8    0.479871\n",
            "Feature 0    0.387705\n",
            "Feature 5    0.087679\n",
            "Feature 1    0.087417\n",
            "Feature 9    0.029419\n",
            "Feature 3    0.022228\n",
            "Feature 7    0.011666\n",
            "Feature 4    0.002457\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, cohen_kappa_score, precision_recall_curve, auc, accuracy_score, matthews_corrcoef\n",
        "\n",
        "# Generate synthetic dataset (or load your dataset)\n",
        "from sklearn.datasets import make_classification\n",
        "data, labels = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Find the optimal C using cross-validation\n",
        "C_values = np.logspace(-3, 3, 10)\n",
        "cv_scores = []\n",
        "\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(C=C, solver='lbfgs', max_iter=1000, random_state=42)\n",
        "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "    cv_scores.append(scores.mean())\n",
        "\n",
        "optimal_C = C_values[np.argmax(cv_scores)]\n",
        "print(f\"Optimal C: {optimal_C}\")\n",
        "\n",
        "# Train Logistic Regression with optimal C\n",
        "model_optimal = LogisticRegression(C=optimal_C, solver='lbfgs', max_iter=1000, random_state=42)\n",
        "model_optimal.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model_optimal, 'logistic_regression_model.pkl')\n",
        "print(\"Model saved successfully.\")\n",
        "\n",
        "# Load the model\n",
        "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# Make predictions with the loaded model\n",
        "y_pred = loaded_model.predict(X_test_scaled)\n",
        "accuracy_optimal = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with loaded model: {accuracy_optimal:.4f}\")\n",
        "\n",
        "# Predict probabilities and evaluate ROC-AUC score\n",
        "y_prob = loaded_model.predict_proba(X_test_scaled)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Predict classes and evaluate Cohen's Kappa Score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Compute Matthews Correlation Coefficient (MCC)\n",
        "mcc_score = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "# Identify important features based on model coefficients\n",
        "feature_importance = pd.Series(loaded_model.coef_[0], index=[f'Feature {i}' for i in range(X_train.shape[1])])\n",
        "feature_importance = feature_importance.abs().sort_values(ascending=False)\n",
        "\n",
        "# Compute Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label=f'PR AUC = {pr_auc:.4f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc_score:.4f}\")\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "id": "vaT5n6dVXzdr",
        "outputId": "0923a99b-3e6b-47a9-a786-f14fbdfa206e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C: 0.021544346900318832\n",
            "Model saved successfully.\n",
            "Model loaded successfully.\n",
            "Accuracy with loaded model: 0.8250\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9103\n",
            "Cohen's Kappa Score: 0.6508\n",
            "Matthews Correlation Coefficient (MCC): 0.6563\n",
            "Feature Importance:\n",
            "Feature 6    0.961881\n",
            "Feature 2    0.732438\n",
            "Feature 8    0.479871\n",
            "Feature 0    0.387705\n",
            "Feature 5    0.087679\n",
            "Feature 1    0.087417\n",
            "Feature 9    0.029419\n",
            "Feature 3    0.022228\n",
            "Feature 7    0.011666\n",
            "Feature 4    0.002457\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "terL9WKsYGEs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}