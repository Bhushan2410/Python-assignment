{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da20582-c170-46d9-878f-3e8998eb1fbd",
   "metadata": {},
   "source": [
    "1. What is Simple Linear Regression?\n",
    "Simple Linear Regression is a statistical method that models the relationship between a dependent variable (Y) and a single independent variable (X) using a linear equation of the form Y = mX + c."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c684a-a9e7-4c4c-8aa0-6a2eec7d0dc6",
   "metadata": {},
   "source": [
    "2. What are the key assumptions of Simple Linear Regression?\n",
    "\n",
    "Linearity: The relationship between X and Y is linear.\n",
    "\n",
    "Independence: Observations are independent of each other.\n",
    "\n",
    "Homoscedasticity: Constant variance of errors.\n",
    "\n",
    "Normality: Residuals are normally distributed.\n",
    "\n",
    "No multicollinearity: Independent variables should not be highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5601bd6-5b2d-4bf0-baaa-d23d1558f213",
   "metadata": {},
   "source": [
    "3. What does the coefficient m represent in the equation Y = mX + c?\n",
    "The coefficient m represents the slope of the regression line, indicating the change in Y for a one-unit increase in X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e9c96-7744-41e2-b7a5-256d2bcc92d5",
   "metadata": {},
   "source": [
    "4. What does the intercept c represent in the equation Y = mX + c?\n",
    "The intercept c represents the value of Y when X is zero, indicating the starting point of the regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5213cf6e-d346-415e-9136-cee2e232a990",
   "metadata": {},
   "source": [
    "5. How do we calculate the slope m in Simple Linear Regression?\n",
    "The slope is calculated using:\n",
    "where  and  are the means of X and Y.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3a3ab-bf76-4a0f-adaa-8d2ed6260b6b",
   "metadata": {},
   "source": [
    "6. What is the purpose of the least squares method in Simple Linear Regression?\n",
    "The least squares method minimizes the sum of squared residuals (differences between \n",
    "observed and predicted values) to find the best-fitting regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f3fdc-6696-44fd-a490-563ea0d45fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression?\n",
    "ùëÖ2 R 2 measures the proportion of variance in the dependent variable explained by the independent variable, ranging from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41056b9-75b2-4bf9-bbf7-c9fe4f11cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. What is Multiple Linear Regression?\n",
    "It extends simple regression to multiple independent variables to model their relationship with a dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c7d05-82eb-4046-8172-029ae6d90a34",
   "metadata": {},
   "source": [
    "9. What is the main difference between Simple and Multiple Linear Regression?\n",
    "Simple regression has one independent variable, whereas multiple regression has two or more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c43775-c566-4b84-845f-539837e9e4f8",
   "metadata": {},
   "source": [
    "10. What are the key assumptions of Multiple Linear Regression?\n",
    "Linearity\n",
    "Independence of residuals\n",
    "Homoscedasticity\n",
    "No perfect multicollinearity\n",
    "Normality of residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca2133-0b5a-464f-b0ea-3be0c2d80201",
   "metadata": {},
   "source": [
    "11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
    "Heteroscedasticity means the variance of residuals changes across values of the independent variable,\n",
    "leading to unreliable standard errors and confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8f81f-c76b-433b-a291-a1236c733a90",
   "metadata": {},
   "source": [
    "12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
    "Remove correlated variables\n",
    "Use Principal Component Analysis (PCA)\n",
    "Apply Ridge or Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe08c072-2610-4bc3-897f-5f5a563fb50f",
   "metadata": {},
   "source": [
    "13. What are some common techniques for transforming categorical variables for use in regression models?\n",
    "One-hot encoding\n",
    "Label encoding\n",
    "Dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9978f1-691d-4501-972a-fec2a72219ae",
   "metadata": {},
   "source": [
    "14. What is the role of interaction terms in Multiple Linear Regression?\n",
    "Interaction terms allow for the effect of one independent variable on \n",
    "Y to depend on another variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c81ca19-e6bd-41e9-84e9-77249042da6c",
   "metadata": {},
   "source": [
    "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
    "In multiple regression, the intercept represents \n",
    "ùëå when all independent variables are zero, but this interpretation can be meaningless if those values are unrealistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a5bfab-ed6c-4c94-8cb7-11ced6b7688d",
   "metadata": {},
   "source": [
    "16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
    "The slope indicates the effect of a one-unit change in an independent variable on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db845d16-be8e-4aac-b2f5-12a3dc2d6f51",
   "metadata": {},
   "source": [
    "17. How does the intercept in a regression model provide context for the relationship between variables?\n",
    "It sets the baseline value of Y when X is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb9ae7-7e81-47be-a24d-bc39a20fd7df",
   "metadata": {},
   "source": [
    "18. What are the limitations of using R¬≤ as a sole measure of model performance?\n",
    "It does not indicate causation.\n",
    "It does not measure model complexity.\n",
    "A high ùëÖ2 does not imply a good model if assumptions are violated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d02276-f064-408a-af3b-e6c681123646",
   "metadata": {},
   "source": [
    "19. How would you interpret a large standard error for a regression coefficient?\n",
    "A large standard error indicates high variability in coefficient estimates, making them less reliable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06305ebd-9911-43b8-a6f9-1f68dcf61921",
   "metadata": {},
   "source": [
    "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
    "It appears as a funnel shape in residual plots; addressing it ensures valid statistical inferences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc3d2be-87f3-42d6-8639-be4f7244aa75",
   "metadata": {},
   "source": [
    "21. What does it mean if a Multiple Linear Regression model has a high R¬≤ but low adjusted R¬≤?\n",
    "It suggests that additional independent variables do not significantly contribute to explaining variance in ùëå\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82b7585-9cd2-4496-b1a7-21ba8c31df5a",
   "metadata": {},
   "source": [
    "22. Why is it important to scale variables in Multiple Linear Regression?\n",
    "Scaling ensures fair comparison among variables and improves convergence in optimization algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facadddb-9795-4a8b-9de2-6282c2880acb",
   "metadata": {},
   "source": [
    "23. What is polynomial regression?\n",
    "A regression technique where the relationship between \n",
    "X and ùëå is modeled using polynomial terms of \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a765506f-0284-48ce-b216-b98d228a5b06",
   "metadata": {},
   "source": [
    "24. How does polynomial regression differ from linear regression?\n",
    "Polynomial regression fits a non-linear curve, whereas linear regression fits a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ce1ff1-d0fc-4bc4-babb-f1532692934c",
   "metadata": {},
   "source": [
    "25. When is polynomial regression used?\n",
    "When data shows a non-linear relationship that a straight line cannot capture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea474f-50a1-4ae0-acfa-f072f1d8f798",
   "metadata": {},
   "source": [
    "26. What is the general equation for polynomial regression?\n",
    "\n",
    "\n",
    "where ùëõ\n",
    "n is the polynomial degree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928af72e-069e-498d-b285-114db391e260",
   "metadata": {},
   "source": [
    "27. Can polynomial regression be applied to multiple variables?\n",
    "Yes, by including polynomial terms for each independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b7a32-801b-4bfe-bc7d-71a0129cfe6e",
   "metadata": {},
   "source": [
    "28. What are the limitations of polynomial regression?\n",
    "Overfitting with high-degree polynomials\n",
    "Computational complexity\n",
    "Extrapolation issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f723d9-e313-4210-8bd7-0cf55a66259c",
   "metadata": {},
   "source": [
    "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
    "Cross-validation\n",
    "Adjusted ùëÖ2\n",
    "Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2249f584-607f-4189-9471-f0da13f10b0b",
   "metadata": {},
   "source": [
    "30. Why is visualization important in polynomial regression?\n",
    "It helps assess model fit and detect underfitting or overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd461422-338f-4f59-aa4a-c8819f50d442",
   "metadata": {},
   "source": [
    "31. How is polynomial regression implemented in Python?\n",
    "Using PolynomialFeatures from sklearn.preprocessing and fitting a linear model:\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1,1)\n",
    "y = np.array([2, 5, 10, 17, 26])\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
